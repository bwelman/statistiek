[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistiek met R",
    "section": "",
    "text": "Inleiding\nDit boek bevat door mij verzamelde notities over het omgaan met statistiek in R.\nVeel voorbeelden zijn afkomstig van internet of uit diverse boeken."
  },
  {
    "objectID": "kansrekenen.html#sec-faculteit",
    "href": "kansrekenen.html#sec-faculteit",
    "title": "1  Kansrekening",
    "section": "1.1 Faculteit",
    "text": "1.1 Faculteit\nEen faculteit kun je berekenen met de functie prod(1:n), maar ook met de speciale functie factorial(n).\n\nVoorbeeld 1.1 Berekening 6!\n\nprod(1:6)\n\n[1] 720\n\nfactorial(6)\n\n[1] 720"
  },
  {
    "objectID": "kansrekenen.html#sec-permutaties",
    "href": "kansrekenen.html#sec-permutaties",
    "title": "1  Kansrekening",
    "section": "1.2 Permutaties",
    "text": "1.2 Permutaties\nHet aantal permutaties is het aantal manieren waarop je een aantal elementen op volgorde kunt leggen. Het aantal mogelijke permutaties van \\(n\\) elementen is gelijk aan \\(n!\\). De mogelijke permutaties kunnen bepaald worden met functie permn() in combinat package\n\nVoorbeeld 1.2 Permutaties van drie kleuren\n\nkleuren <- c(\"rood\", \"wit\", \"blauw\")\nn <- length(kleuren)\nfactorial(n)          # Aantal permutaties\n\n[1] 6\n\ncombinat::permn(kleuren)        # Mogelijke permutaties\n\n[[1]]\n[1] \"rood\"  \"wit\"   \"blauw\"\n\n[[2]]\n[1] \"rood\"  \"blauw\" \"wit\"  \n\n[[3]]\n[1] \"blauw\" \"rood\"  \"wit\"  \n\n[[4]]\n[1] \"blauw\" \"wit\"   \"rood\" \n\n[[5]]\n[1] \"wit\"   \"blauw\" \"rood\" \n\n[[6]]\n[1] \"wit\"   \"rood\"  \"blauw\""
  },
  {
    "objectID": "kansrekenen.html#sec-variaties",
    "href": "kansrekenen.html#sec-variaties",
    "title": "1  Kansrekening",
    "section": "1.3 Variaties",
    "text": "1.3 Variaties\nHet aantal variaties van \\(k\\) elementen uit een totaal van \\(n\\) elementen is het aantal verschillende volgorden van \\(k\\) elementen uit \\(n\\) elementen.\nAantal variaties = \\(\\frac{n!}{(n-k)!}\\)\n\nVoorbeeld 1.3 Uit een vereniging van 12 leden moet een bestuur van 2 leden (voorzitter en penningmeester) gekozen worden. Hoeveel verschillende besturen zijn mogelijk? let er op dat een bestuur van voorzitter A en penningmeester B een ander bestuur is dan voorzitter B en penningmeester A.\nDit is het aantal variaties van 2 uit 12 = \\(\\frac{12!}{(12-2)!} = 11*12 = 132\\)"
  },
  {
    "objectID": "kansrekenen.html#sec-combinaties",
    "href": "kansrekenen.html#sec-combinaties",
    "title": "1  Kansrekening",
    "section": "1.4 Combinaties",
    "text": "1.4 Combinaties\nHet aantal combinaties is het aantal verschillende groepen van \\(k\\) elementen uit een totaal van \\(n\\) elementen is \\(\\frac{n!}{(n-k)!k!}\\). Dit heet ook wel n over k. De volgorde binnen de groep is niet van belang. Hiervoor R een eigen functie choose(n,k).\n\nVoorbeeld 1.4 Hoeveel combinaties van twee letters uit een totaal van 4 letters (A,B,C,D) zijn mogelijk? Nu doet de onderlinge volgorde er niet toe, AB is hetzelfde als BA.\n\n# via faculteiten\nfactorial(4)/(factorial(2)*factorial(4-2))\n\n[1] 6\n\n# via functie\nchoose(4,2)\n\n[1] 6\n\n\nDe mogelijke combinaties zelf kunnen bepaald worden met de functie combn().\n\nx <- LETTERS[1:4]\nx\n\n[1] \"A\" \"B\" \"C\" \"D\"\n\ncombn(x, 2)\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,] \"A\"  \"A\"  \"A\"  \"B\"  \"B\"  \"C\" \n[2,] \"B\"  \"C\"  \"D\"  \"C\"  \"D\"  \"D\""
  },
  {
    "objectID": "kansrekenen.html#sec-groepen",
    "href": "kansrekenen.html#sec-groepen",
    "title": "1  Kansrekening",
    "section": "1.5 Aantal groepen met teruglegging",
    "text": "1.5 Aantal groepen met teruglegging\nAls een element dat gekozen is bij een trekking, de volgende keer weer kan verschijnen, dan wordt dat trekken met teruglegging genoemd.\nAantal groepen van \\(k\\) elementen uit \\(n\\) elementen met teruglegging = \\(n^k\\).\n\nVoorbeeld 1.5 Een persoon heeft twee letters als initialen, hoeveel mogelijkheden zijn er? Let er op dat AB en BA verschillende gevallen zijn.\nAantal groepen = \\(26^2 = 676\\)"
  },
  {
    "objectID": "kansrekenen.html#sec-notaties",
    "href": "kansrekenen.html#sec-notaties",
    "title": "1  Kansrekening",
    "section": "1.6 Notaties",
    "text": "1.6 Notaties\nDe letter \\(P\\) wordt gebruikt om de kans (Probability) aan te geven.\nVoorbeelden voor een spel van 52 speelkaarten.\n\n\\(P(hartenaas) = \\frac{1}{52}\\)\n\\(P(rood) = \\frac{26}{52} = \\frac{1}{2}\\)\n\\(P(aas) = \\frac{4}{52} = \\frac{1}{13}\\)\n\\(P(rood EN aas) = P(rood) * P(aas) = \\frac{1}{2} * \\frac{1}{13} = \\frac{1}{26}\\)\n\nVoorwaardelijke kans\nAls A en B twee gebeurtenissen zijn, wordt de voorwaardelijke kans dat A zich voordoet, gegeven dat B heeft plaatsgevonden, geschreven als \\(P(A|B)\\).\nZo kun je de kans op een aas, gegeven dat er een rode kaart is getrokken, weergeven als \\(P(aas|rood)\\). Deze kans is \\(\\frac{2}{26} = \\frac{1}{13}\\). Immers er zijn 26 rode kaarten waaronder 2 azen.\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\text{ of } P(A \\cap B) = P(A|B) \\times P(B)\\]\nOnafhankelijke gebeurtenissen\nBij onafhankelijke gebeurtenissen A (worp met munt) en B (worp met dobbelsteen) is \\(P(A|B) = P(A)\\). In dat geval is \\(P(A \\cap B) = P(A) \\times P(B)\\), dus het product van de individuele kansen."
  },
  {
    "objectID": "kansverdelingen.html#sec-verd-dichtheid",
    "href": "kansverdelingen.html#sec-verd-dichtheid",
    "title": "2  Kansverdelingen",
    "section": "2.1 Kans(dichtheid)functie en Verdelingsfunctie",
    "text": "2.1 Kans(dichtheid)functie en Verdelingsfunctie\nZowel bij discrete kansvariabelen \\(\\underline{k}\\) als continue kansvariabelen \\(\\underline{x}\\) heb je een verzameling van uitkomsten die bestaat uit reële getallen. De beschrijving van de kansen op de diverse uitkomsten heet de kansfunctie (in het discrete geval) of de kansdichtheid (in het continue geval). Soms kan het handig zijn om te rekenen met cumulatieve kansen, dan wordt gewerkt met de (cumulatieve) verdelingsfunctie.\nEngelstalig:\n\nPDF = Probability Density Function (kansdichtheidfunctie)\nCDF = cumulative distribution function (verdelingsfunctie)\nQ(p) = Quantile function\n\ndiscrete variabelen\n\nkansvariabele \\(\\underline{k}\\)\nkansfunctie \\(f(k) = P(\\underline{k} = k)\\)\nverdelingsfunctie \\(F(k) = P(\\underline{k} \\le k)\\)\n\ncontinue variabelen\n\nkansvariabele \\(\\underline{x}\\)\nkansdichtheid \\(f(x)\\)\nverdelingsfunctie \\(F(x) = \\int_{-\\infty}^{x}f(y)dy\\)\n\nDe cumulatieve kansverdeling \\(F(x)\\) wordt berekend als de integraal van de kansdichtheid \\(f(x)\\). Omgekeerd kan de kansdichtheid berekend worden als de afgeleide van de verdelingsfunctie: \\(f(x) = F'(x)\\)"
  },
  {
    "objectID": "kansverdelingen.html#sec-verd-functies",
    "href": "kansverdelingen.html#sec-verd-functies",
    "title": "2  Kansverdelingen",
    "section": "2.2 Verdelingsfuncties in R",
    "text": "2.2 Verdelingsfuncties in R\nR heeft standaard functies voor de meeste kansverdelingen. Voor elke kansverdeling zijn steeds vier functies beschikbaar die steeds beginnen met een van de volgende voorvoegsels: d, p, q of r:\n\nd : kansdichtheidsfunctie (PDF), geeft de kans op waarde x.\np : Cumulatieve verdelingsfunctie (CDF), geeft de kans op een waarde <= x.\nq : Inverse cumulatieve kansfunctie (quantile function), geeft de waarde behorend bij een kans <= p% (kwantiel)\nr : Genereert random getallen uit de verdeling\n\nDe functienamen bestaan uit een voorvoegsel (d, p, q, r) en een achtervoegsel welke de desbetreffende verdeling aangeeft.\n\n\n\n\n\n\n\n\nDiscrete verdeling\nR naam\nParameters\n\n\n\n\nBinomiaal\nbinom\nn = aantal trekkingen; p = kans op succes voor een trekking\n\n\nGeometrisch\ngeom\np = kans op succes voor een trekking\n\n\nHypergeometrisch\nhyper\nm = aantal witte ballen in de pot; n = aantal zwarte ballen in de pot; k = aantal trekkingen\n\n\nNegatief binomiaal (NegBinomial)\nnbinom\nsize = aantal succesvolle trekkingen; of prob = kans op succes of mu = gemiddelde\n\n\nPoisson\npois\nlambda = gemiddelde\n\n\n\n\n\n\n\n\n\n\n\nContinue verdeling\nR naam\nParameters\n\n\n\n\nBeta\nbeta\na (vorm 1); b (vorm 2)\n\n\nCauchy\ncauchy\nlocation; scale\n\n\nChikwadraat (Chisquare)\nchisq\ndf = aantal vrijheidsgraden\n\n\n(Negatief) Exponentieel\nexp\nrate (snelheid)\n\n\nF\nf\ndf1 en df2 = aantal vrijheidsgraden\n\n\nGamma\ngamma\nrate; of rate of scale\n\n\nLog-normal (Lognormal)\nlnorm\nmeanlog = gemiddelde; sdlog = standaardafwijking (beide op logaritmische schaal)\n\n\nLogistisch\nlogis\nlocation; scale\n\n\nNormaal\nnorm\nmean = gemiddelde; sd = standaardafwijking\n\n\nStudent’s t (TDist)\nt\ndf = aantal vrijheidsgraden\n\n\nUniform\nunif\nmin = ondergrens; max = bovengrens\n\n\nWeibull\nweibull\nshape; scale\n\n\nWilcoxon\nwilcox\nm = aantal waarnemingen in eerste steekproef; n = aantal waarnemingen in tweede steekproef\n\n\n\n\n\n\n\n\n\nBelangrijk\n\n\n\nBelangrijk, zet bij het genereren van random getallen altijd eerst set.seed() wanneer de random getallen gereproduceerd moet kunnen worden. Voor goede uitleg zie ook Probability Distributions in R (Stat 5101, Geyer).\n\n\n\n2.2.1 Bernoulli verdeling\nDit is een discrete kansverdeling die een experiment beschrijft met als enige uitkomsten succes of mislukking. Hierbij neemt de kansvariabele \\(X\\) de waarde 1 aan bij succes en 0 bij mislukking. Een voorbeeld is het opgooien van een munt, met \\(p\\) als de kans op succes (bijvoorbeeld kop boven).\n\\(P(X = 1) = p\\) en \\(P(X = 0) = 1 - p\\)\nDe kansfunctie kan ook geschreven worden als\n\\[\nf(k;p)= \\left \\{ \\begin{array}{ll}\n        p & \\mbox{als $k = 1$}\\\\\n      1-p & \\mbox{als $k = 0$}\\\\\n        0 & \\mbox{anders} \\end{array}\n\\right \\}\n\\]\nDeze uitdrukking kan ook geschreven worden als\n\\(f(k;p) = pk+(1-p)(1-k)\\) voor \\(k \\in \\{0,1\\}\\)\nVerwachtingswaarde = \\(E(X) = p\\) en variantie = \\(Var(X) = p(1-p)\\).\nAls je een Bernoulli experiment meerdere malen na elkaar uitvoert, dan heet dat een binomiaal kansexperiment. Als \\(X_1, X_2, ..., X_n\\) onafhankelijke, identiek verdeelde kansvariabelen zijn, die alle Bernoulli verdeeld zijn met kans op succes \\(p\\), dan is \\(Y = \\sum_{k=1}^{n} X_k\\) een binomiaal verdeelde variabele met parameters \\(n\\) en \\(p\\).\nBasis R heeft geen functies voor Bernoulli verdelingen. Deze zijn wel beschikbaar in package Rlab als dbern, pbern, qbern en rbern.\n\nVoorbeeld 2.1 Genereer 20 random getallen uit een Bernoulli verdeling met kans op succes 0,3.\n\nset.seed(25)\nRlab::rbern(n=20, prob=0.3)\n#>  [1] 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n\nJe zou dit in standaard R kunnen nabootsen met de functie sample.\n\nset.seed(25)\nsample(c(0, 1), size = 20, replace=T, prob = c(0.7, 0.3))\n#>  [1] 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n\n\n\n\n2.2.2 Binomiale verdeling\nDe binominale (bi = twee, nominaal = categorieën) verdeling is een verdeling van het aantal successen in een reeks van \\(n\\) onafhankelijke Bernoulli experimenten. Voor \\(n=1\\) is de verdeling gelijk aan een Bernoulli verdeling.\nEen Bernoulli variabele is een variabele met twee mogelijke uitkomsten:\n\nsucces (= 1) met kans \\(p\\)\ngeen succes (= 0) met kans \\(q = 1-p\\)\n\nEen binomiale verdeling is de som van een aantal (n) onafhankelijke en identiek verdeelde Bernoulli variabelen.\nVoor n trekkingen met kansvariabele X geldt\n\nnotatie: \\(X \\sim B(n, p)\\)\nVerwachting: \\(E(X) = np\\)\nVariantie: \\(Var(X) = np(1-p)\\)\nkansfunctie: \\(f(k;n,p) = P(X = k) = \\binom{n}{k} p^k(1-p)^{n-k}\\)\n\n\nVoorbeeld 2.2 Er wordt 10 keer geworpen met een eerlijke munt. Wat is de kans op een bepaald aantal keren kop? In de volgende figuur is dit experiment 10.000 keer gesimuleerd.\n\n\n\n\n\nFiguur 2.1: Kans van het aantal keren kop bij 10 worpen.\n\n\n\n\n\nR-Functies: dbinom(), pbinom(), qbinom(), rbinom()\n\ndbinom\ndbinom(x ,size = n, prob = p) geeft de kans op x successen bij n experimenten waarbij p de met kans op succes is.\n\nVoorbeeld 2.3 Bij 2 worpen met een eerlijk muntstuk (dus p = 0.5) zijn de mogelijke uitkomsten: kop-kop, kop-munt, munt-kop, munt-munt. De kans op succes (kop) is 0.5 Dit geeft\n\nx <- c(0, 1, 2)\ndbinom(x, size = 2, prob = 0.5)\n#> [1] 0.25 0.50 0.25\n\nDus\n\n\n\nx (aantal kop)\np (kans)\n\n\n\n\n0\n0.25\n\n\n1\n0.50\n\n\n2\n0.25\n\n\n\nStel je gooit 10 keer met een eerlijke dobbelsteen. Wat is de kans dat je precies twee keer een zes gooit?\n\ndbinom(2, size = 10, prob = 1/6)\n#> [1] 0.291\n\n\n\n\npbinom\nWat is de kans op 10 of minder goede antwoorden bij het willekeurig invullen van veertig 4-keuzevragen?\n\nVoorbeeld 2.4 Bij het willekeurig invullen van een 4-keuzevraag is de kans op succes (antwoord goed) 0.25 en de kans op geen succes 0.75\n\npbinom(10, size = 40, prob = 0.25)\n#> [1] 0.584\n\n\n\n\nrbinom\n\nVoorbeeld 2.5 Een school heeft 2000 leerlingen, waarvan 50% meisjes en 50% jongens. Deze leerlingen worden verdeeld over 100 klassen met in elke klas 20 leerlingen. Wat is de kansverdeling van het aantal meisjes in elke klas?\nDat zijn 100 trekkingen uit een binomiale verdeling met grootte 20 en kans op succes (is meisje) van 0.5\n\nset.seed(30)\naantalmeisjes <- rbinom(n = 100, size = 20, prob = 0.5)\ntable(aantalmeisjes)\n#> aantalmeisjes\n#>  4  5  6  7  8  9 10 11 12 13 14 15 16 \n#>  1  1  7 10 15 16 17 13  7  8  2  2  1\nhist(aantalmeisjes, main = \"Histogram aantal meisjes\")\nbarplot(table(aantalmeisjes), main = \"Kolomdiagram aantal meisjes\")\n\n\n\n\n\n\n\n(a) Histogram\n\n\n\n\n\n\n\n(b) Kolomdiagram\n\n\n\n\nFiguur 2.2: Trekkingen uit een binomiale verdeling.\n\n\n\n\n\n\n\n2.2.3 Poisson verdeling\nKansfunctie: \\(f(x) = P(X=x) =e^{-\\mu \\frac{\\mu^x}{x!}}\\) voor \\(x = 0, 1, 2, \\dots\\)\nR-Functies: dnpois(), ppois(), qpois(), rpois()\nEen Poisson-verdeling is een soort binomiale verdeling met een grote \\(n\\) en een kleine \\(p\\). Voorbeeld: aantal verkeersongelukken per dag. Vaak speelt de tijd een rol bij de Poisson-verdeling.\n\n\\(k \\sim Poisson(\\mu)\\)\n\\(E(k) = Var(k) = \\mu = \\lambda * t\\) met \\(\\lambda\\) = aantal successen per tijdseenheid.\n\n\ndpois\nStel dat het aantal biefstukken dat in een restaurant per dag besteld wordt een Poisson verdeling met een gemiddelde van 20 volgt. Wat is de kans dat op een dag precies 25 biefstukken besteld worden?\n\ndpois(25, lambda = 20)\n#> [1] 0.0446\n\n\n\nqpois\nEen vervolg op de voorgaande vraag. Wanneer het restaurant aan ten minste 80% van de vraag naar biefstukken wil voldoen, hoeveel biefstukken moeten dan beschikbaar zijn?\n\nqpois(0.80, 20)\n#> [1] 24\n\n\n\nrpois\nrpois(n, lambda) genereert \\(n\\) trekkingen uit een Poissonverdeling met een verwachtingswaarde \\(\\lambda\\).\n\nVoorbeeld 2.6  \n\nset.seed(35)\nx <- rpois(n = 1000, lambda = 4)\ntable(x)\n#> x\n#>   0   1   2   3   4   5   6   7   8   9  10  11  12  13 \n#>  12  69 146 197 207 133 114  72  30   9   7   2   1   1\nbarplot(table(x))\n\n\n\n\nFiguur 2.3: 1000 trekkingen uit een Poisson(4) verdeling.\n\n\n\n\n\n\nVoorbeeld 2.7 Er moeten 100 groepen gemaakt worden, elk bestaande uit 5 getallen uit een Poisson verdeling met een gemiddelde van 10. Hierbij wordt gebruik gemaakt van de functie replicate() die een matrix maakt 100 kolommen en 20 rijen.\n\nset.seed(38)\nmy_pois <- replicate(100, rpois(n = 5, lambda = 10))\nkolomgemiddeldes <- colMeans(my_pois)  # kolomgemiddeldes\nhist(kolomgemiddeldes)\n\n\n\n\nFiguur 2.4: 100 herhalingen van 5 trekkingen uit een Poisson(10) verdeling.\n\n\n\n\nOpm.: De verdeling begint een beetje op een normale verdeling te lijken (gevolg centrale limietstelling)\n\n\n\n\n2.2.4 Normale verdeling\nDe normale verdeling geeft de kans weer dat een bepaalde waarde voorkomt voor een continue variabele.\nKansdichtheid: \\(f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x - \\mu}{\\sigma})^2}\\)\nR-Functies: dnorm(), pnorm(), qnorm(), rnorm()\n\ndnorm\nSyntax: dnorm(x, mean=0, sd=1, log=FALSE)\n\nx <- seq(from = -5, to = 5, length.out = 100) # 100 waarden, lopend van -5 tot 5\nf <- dnorm(x)\nplot(x, f, type = \"l\", xlab = \"x\", ylab = \"f(x)\", main =\"\")\nF <- pnorm(x)\nplot(x, F, type = \"l\", xlab = \"x\", ylab = \"F(x)\", main = \"\")\n\n\n\n\n\n\n\n(a) Kansdichtheidsfunctie\n\n\n\n\n\n\n\n(b) Cumulatieve verdelingsfunctie\n\n\n\n\nFiguur 2.5: Normale verdeling\n\n\n\n\n\npnorm\nSyntax: pnorm(x, mean=0, sd=1, lower.tail=TRUE, log.p=FALSE)\nGeeft de cumulatieve verdelingsfunctie (CDF). Voor lower.tail = TRUE (defaultwaarde) worden de kansen berekend voor \\(P(\\underline{x} \\le x)\\) en voor lower.tail = FALSE de kansen \\(P(\\underline{x} \\gt x)\\).\n\npnorm(0)     # 50% ligt onder het gemiddelde 0\n#> [1] 0.5\npnorm(-2)    # 2.3% ligt meer dan 2 standaarddeviaties onder het gemiddelde\n#> [1] 0.0228\npnorm(1.96)  # 97.5% ligt dus links van de waarde z=1, dus 2.5% rechts daarvan\n#> [1] 0.975\npnorm(1.96) - pnorm(-1.96)       # 95% ligt tussen de waarden z=-1.96 en z=1.96\n#> [1] 0.95\npnorm(12, mean = 10, sd = 2, lower.tail = FALSE) # 15.9% kans op waarde groter dan 12 bij N(10,2)\n#> [1] 0.159\n1 - pnorm(12, mean = 10, sd = 2)                 # alternatieve manier\n#> [1] 0.159\n\n\n\nqnorm\nSyntax: qnorm(p, mean=0, sd=1, lower.tail=TRUE, log.p=FALSE)\nMet deze functie kun je het kwantiel (percentiel) Q vinden voor elke kans p.\n\nqnorm(0.5)    # 50% quantiel is de mediaan, hier tevens het gemiddelde\n#> [1] 0\nqnorm(0.975)  # De waarde bij het 97.5% quantiel\n#> [1] 1.96\nqnorm(0.975, lower.tail = FALSE) # 97.5% ligt boven deze waarde\n#> [1] -1.96\nqnorm(0.025)                     # hetzelfde als voorgaande\n#> [1] -1.96\n\nEen illustratie van het 75% quantiel.\n\n# Maak een grafiek van de N(0,1) verdeling\nx <- seq(from = -5, to = 5, length.out = 100)\nf <- dnorm(x)\nnframe <- data.frame(x = x, y = f)\n# Bereken het 75% quantiel (percentiel)\nline <- qnorm(0.75)\nxstr <- sprintf(\"qnorm(0.75) = %1.3f\", line)\n\n# Het deel van de N(0,1) verdeling links van het 75% percentiel\nnframe75 <- subset(nframe, nframe$x < line)\n# Maak tekening\n# Het grijze gebied is 75% van het oppervlak onder de normaal grafiek\nggplot(nframe, aes(x = x, y = y)) + geom_line() +\n  geom_area(data = nframe75, aes(x = x, y = y), fill = \"gray\") +\n  geom_vline(aes(xintercept = line), linetype = 2) +\n  geom_text(x = line, y = 0, label = xstr, vjust = 1)\n\n\n\n\nFiguur 2.6: Grafiek van een N(0,1) verdeling met 75% percentiel.\n\n\n\n\n\n\nrnorm\nSyntax: rnorm(n, mean=0, sd=1)\n\n# trek 1000 waarden uit een N(0,1) verdeling\nu <- rnorm(1000)\nhead(u)\n#> [1] -0.610 -0.426 -1.169 -1.532 -0.150 -1.361\n\n\n\n\n2.2.5 Uniforme verdeling\nEen verdeling is uniform wanneer elke mogelijke uitkomst een gelijke kans van optreden heeft. Stel je trekt een naam uit een hoed met 12 namen trekken. Elke naam heeft evenveel kans om getrokken te worden (\\(p = \\frac{1}{12}= .0833\\)). Als je deze verdeling zou visualiseren, zou het er als volgt uitzien:\n\n\n\n\n\nFiguur 2.7: Uniforme verdeling.\n\n\n\n\nKansdichtheid:\n\n\\(f(x) = \\frac{1}{b-a}\\) voor \\(a \\le x \\le b\\)\n\\(f(x) = 0\\) voor \\(x < a\\) of \\(x > b\\)\n\nVerdelingsfunctie:\n\n\\(F(x) = 0\\) voor \\(x < a\\)\n\\(F(x) = \\frac{x-a}{b-a}\\) voor \\(a \\le x \\le b\\)\n\\(F(x) = 1\\) voor \\(x > b\\)\n\nR-Functies: dunif(), punif(), qunif(), runif()\n\nrunif\nrunif(n, min=a, max=b) genereert n trekkingen uit een uniforme verdeling op het interval van a tot b.\n\n\n\n2.2.6 (Negatief) Exponentiële verdeling\nKansdichtheid:\n\n\\(f(x) = \\lambda e^{-\\lambda x}\\) voor \\(x \\ge 0\\) en \\(\\lambda \\gt 0\\)\n\\(f(x) = 0\\) voor \\(x < 0\\)\n\nVerdelingsfunctie:\n\n\\(F(x) = 1 - e^{-\\lambda x}\\) voor \\(x \\ge 0\\)\n\\(F(x) = 0\\) voor \\(x < 0\\)\n\nR-Functies: dexp(), pexp(), qexp(), rexp()\n\npexp\nDe levensduur van een bepaald type gloeilamp volgt een exponentiële verdeling met een gemiddelde tijd van 24 maanden. Wat is de kans dat een willekeurige gloeilamp binnen de eerste zes maanden kapot gaat? En wat is de kans dat een gloeilamp meer dan 4 jaar (48 maanden) meegaat?\n\npexp(6, 1/24)  # kans kapot in eerste 6 maanden\n#> [1] 0.221\npexp(48, 1/24, lower.tail = FALSE) # kans op meer dan 4 jaar goed\n#> [1] 0.135\n\n\n\nqexp\nEen vervolg op de voorgaande gloeilampvraag. Na hoeveel maanden is 40% van de gloeilampen kapot?\n\nqexp(0.4, 1/24)\n#> [1] 12.3\n\n\n\n\n2.2.7 Chi-kwadraat verdeling\n\\(E_{\\chi^2} = 1\\) en \\(var_{\\chi^{2}[n]} = 2n\\)\nR-Functies: dchisq(), pchisq(), qchisq(), rchisq()\n\nqchisq\nBeneden welke grens ligt het 95% gebied van een \\(\\chi^{2}[6]\\) verdeling?\n\nqchisq(p = 0.95, df = 6)\n#> [1] 12.6\n\n\n\n\n2.2.8 t verdeling\nVoor kleine steekproeven uit een normale verdeling met onbekende \\(\\sigma\\). Advies:\n\nnormale verdeling + bekende \\(\\sigma\\) -> normale verdeling\nnormale verdeling + onbekende \\(\\sigma\\):\n\n\\(n \\le 30\\) -> t-verdeling\n\\(n \\gt 30\\) -> normale verdeling\n\n\nR-Functies: dt(), pt(), qt(), rt()\n\n\n2.2.9 Beta verdeling\nR-Functies: dbeta(), pbeta(), qbeta(), rbeta()\nDe beta verdeling is een continue kansverdeling gedefinieerd op het interval [0,1] en heeft twee niet negatieve parameters \\(\\alpha\\) en \\(\\beta\\) die de vorm bepalen. De verdeling wordt o.a. gebruikt bij het modelleren van tijdsuren voor projecten.\n\\(\\mu =\\frac{\\alpha}{\\alpha + \\beta}\\) en \\(\\sigma^2 = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\).\nOplossen voor \\(\\alpha\\) en \\(\\beta\\) geeft\n\\(\\alpha = (\\frac{1 - \\mu}{\\sigma^2} - \\frac{1}{\\mu}) \\mu^2\\) en \\(\\beta = \\alpha (\\frac{1}{\\mu} - 1)\\)\n\ndbeta\nSyntax: dbeta(x, shape1, shape2, ncp = 0, log = FALSE)\n\nx <- seq(0, 1, by = 0.02)\ny <- dbeta(x, shape1 = 2, shape2 = 5)\nplot(x, y)\n\n\n\n\n\n\n\n\n\n\npbeta\nSyntax: pbeta(q, shape1, shape2, ncp = 0, lower.tail = TRUE, log.p = FALSE)\nAls voorbeeld een cumulatieve verdelingsfunctie.\n\ny <- pbeta(x, shape1 = 2, shape2 = 5)\nplot(x, y)\n\n\n\n\n\n\n\n\n\n\nqbeta\nSyntax: qbeta(p, shape1, shape2, ncp = 0, lower.tail = TRUE, log.p = FALSE)\n\ny <- qbeta(x, shape1 = 2, shape2 = 5)\nplot(x, y)\n\n\n\n\n\n\n\n\n\n\nrbeta\nSyntax: rbeta(n, shape1, shape2, ncp = 0)\n\nset.seed(12345)\naantal <- 1000\nx <- rbeta(n = aantal, shape1 = 1, shape2 = 5)\nhead(x)\n#> [1] 0.0719 0.0591 0.1923 0.2934 0.0670 0.2374\nplot(density(x), main=\"Beta verdeling\", ylab = \"Dichtheid\")\n\n\n\n\nFiguur 2.8: ?(caption)\n\n\n\n\n\n\n\n2.2.10 Lognormale verdeling\nEen lognormale verdeling is een continue kansverdeling van een variabele waarvan de logaritme normaal verdeeld is. Dus als de variabele X lognormaal verdeeld is, dan heeft Y = ln(X) een normale verdeling. Op analoge wijze, als Y een normale verdeling heeft, dan heeft de exponentiële functie van Y, X = exp(Y) een lognormale verdeling.\nEen lognormaal verdeelde variabele heeft alleen positieve waarden. Het is een handig en nuttig model voor metingen in exacte en technische wetenschappen, maar ook in geneeskunde , economie en andere onderwerpen (bijv. energieën, concentraties, lengtes, financiële opbrengsten en andere statistieken).\nR-Functies: dlnorm(), plnorm(), qlnorm(), rlnorm()"
  },
  {
    "objectID": "kansverdelingen.html#sec-verd-standaardiseren",
    "href": "kansverdelingen.html#sec-verd-standaardiseren",
    "title": "2  Kansverdelingen",
    "section": "2.3 Standaardiseren",
    "text": "2.3 Standaardiseren\nDe Z-score of Z-waarde is de gestandaardiseerde vorm van een variabele en wordt berekend via \\(z = \\frac{x - \\mu}{\\sigma}\\).\nOm deze waarden te bepalen kun je de functie scale(x) gebruiken. Wanneer je scale(x, scale = FALSE) toepast dan wordt alleen \\(x - \\mu\\) berekend, de waarden worden dan gecentreerd.\n\nx <- rnorm(n = 10, mean = 50, sd = 5)\nsummary(x)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    39.8    45.6    49.9    49.0    52.8    56.7\nsd(x)\n#> [1] 5.28\n\n\nzx <- scale(x)\nsummary(zx)\n#>        V1        \n#>  Min.   :-1.736  \n#>  1st Qu.:-0.649  \n#>  Median : 0.171  \n#>  Mean   : 0.000  \n#>  3rd Qu.: 0.721  \n#>  Max.   : 1.463\nsd(zx)\n#> [1] 1\n\n\n\n\n\n\n\nOpmerking\n\n\n\nBij een dataframe kun je ook gebruiken maken van de functie mutate() uit package dplyr via\nmutate(zscore = (variabele - mean(variabele) / sd(variabele))"
  },
  {
    "objectID": "kansverdelingen.html#sec-verd-normaliteit",
    "href": "kansverdelingen.html#sec-verd-normaliteit",
    "title": "2  Kansverdelingen",
    "section": "2.4 Normaliteit toetsing",
    "text": "2.4 Normaliteit toetsing\nBij nogal wat statistische methoden wordt er vanuit gegaan dat de dataset een bepaalde statistische verdeling volgt, vaak een normale verdeling. Voordat je met die methode aan de slag gaat moet je wel eerst controleren of deze aanname klopt.\n\n2.4.1 Visuele controle\n\nHistogram\n\nhist(trees$Height, xlab = \"Hoogte (ft)\", main = \"Histogram boomhoogte\")\n\n\n\n\nFiguur 2.9: Histogram hoogte zwarte kersenbomen\n\n\n\n\nHistogrammen zijn niet voldoende, vooral niet bij kleine steekproeven (kleiner dan 20)\n\n\nDichtheidsgrafiek\n\nplot(density(trees$Height), main = \"Dichtheidsgrafiek\")\n\n\n\n\nFiguur 2.10: Dichtheid hoogte zwarte kersenbomen\n\n\n\n\n\n\nQQ plot\nOm te beoordelen of twee gegevensverzamelingen dezelfde kansverdelingen volgen kun je gebruik maken van een Quantiel-Quantiel (Q-Q) grafiek. Dit is in feite een spreidingsdiagram waarin de quantielen van de twee verzamelingen tegen elkaar uitgezet worden. Wanneer de verdelingen gelijke vormen hebben dan liggen deze punten nagenoeg op een rechte lijn. Het is slechts een visuele verificatie en geen volledig bewijs.\n\nqqplot(x = rnorm(n=100, mean = 50, sd = 3), y = rnorm(n=200, mean = 50, sd = 3))\n\n\n\n\nFiguur 2.11: QQ plot van een gegenereerde N(50,3) verdeling.\n\n\n\n\nTwee gegevensverzamelingen met elkaar vergelijken komt niet zo vaak voor. Veel vaker wordt de verdeling van een verzameling (een steekproef) vergeleken met een theoretische verdeling (normale verdeling, …).\nqqnorm\nVoor het vergelijken met een normale verdeling kent R een speciale qqplot functie qqnorm(y). Hiermee kun je dus visueel beoordelen of de verdeling van de te onderzoeken gegevens op een normale verdeling lijkt.\nR heeft ook een functie qqline(y) die als extra nog een lijn in de qqnorm grafiek tekent. Met deze lijn kun je nog gemakkelijker beoordelen of de verdeling van een normale verdeling afwijkt. Je moet deze opdracht dan wel direct na de qqnorm functie geven.\n\nqqnorm(trees$Height)\nqqline(trees$Height, col = \"steelblue\", lwd = 2)\n\n\n\n\nFiguur 2.12: QQ plot voor hoogte zwarte kersenbomen\n\n\n\n\nDe afwijkingen t.o.v. de lijn zeggen iets over de scheefheid (skew) van de verdeling.\n\nPackage car heeft ook een qqPlot() functie die voor een betere visualisatie zorgt.\n\n\n\n\n2.4.2 Normaliteitstest\nVisuele inspectie kan soms onbetrouwbaar zijn. Er zijn ook toetsen beschikbaar om formeel te testen of gegevens een een normale verdeling volgen. Een veel gebruikte toets is Shapiro-Wilk’s met de volgende hypotheses:\n\n\\(H_0\\): de gegevens volgen een normale verdeling\n\\(H_1\\): de gegevens volgen geen normale verdeling\n\n\nshapiro.test(trees$Height)\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  trees$Height\n#> W = 1, p-value = 0.4\n\nDe p-waarde is groter dan 0,05, de nulhypothese wordt niet verworpen, de gegevens volgen een normale verdeling.\nHet is belangrijk op te merken dat normaliteitstoetsen in de praktijk vaak als te conservatief worden beschouwd in de zin dat voor een grote steekproef (n> 50) een kleine afwijking van de normaliteit ertoe kan leiden dat de normaliteitsconditie wordt geschonden. Het is een is een hypothesetoetsing, dus naarmate de steekproefomvang toeneemt, neemt hun vermogen om kleinere verschillen te detecteren toe. Dus naarmate het aantal waarnemingen toeneemt, wordt de Shapiro-Wilk-toets zeer gevoelig, zelfs voor een kleine afwijking van de normaliteit. Het kan dus voorkomen dat volgens de toets de gegevens niet normaal verdeeld zijn, terwijl de afwijkingen van de normale verdeling te verwaarlozen zijn. Om deze reden wordt de normaliteitsvoorwaarde vaak geverifieerd op basis van een combinatie van zowel visuele inspectie (met name de QQ grafiek) en een formele toetsing."
  },
  {
    "objectID": "kansverdelingen.html#sec-verd-kwantielen",
    "href": "kansverdelingen.html#sec-verd-kwantielen",
    "title": "2  Kansverdelingen",
    "section": "2.5 Kwantielen",
    "text": "2.5 Kwantielen\nEen kwantiel is een getal dat een dataset verdeelt in twee delen, de kleinere en de grotere waarden. Zo geeft het 0,85-kwantiel een verdeling met een fractie 0,85 kleinere waarden en een fractie 0,15 grotere waarden. Deze waarde wordt aangegeven met \\(Q(0,85)\\) Bekend is het 0,5-kwantiel, de mediaan genaamd, die het midden is van een geordende dataset.\n\n\n\n\n\n\nOpmerking\n\n\n\nHet concept van kwantiel is nauw verbonden met het concept van percentiel. Wanneer iemand op een toets een percentielscore van 85 heeft, betekent dat 85% van alle deelnemers bij die toets dezelfde of een lagere score heeft en 15% van de deelnemers een hogere score heeft. Het enige verschil tussen percentiel en kwantiel is dat percentiel verwijst naar een percentage van de verzameling gegevens en kwantiel verwijst naar een fractie van de verzameling gegevens.\n\n\nVoor een verzameling van \\(n\\) getallen \\(x_1, x_2, ..., x_n\\), waaronder mogelijk gelijke, wordt het \\(p\\)-kwantiel \\(x_p\\) bepaald door de eisen:\n\nten minste \\(pn\\) van de data zijn kleiner dan of gelijk aan \\(x_p\\).\nten minste \\((1-p)n\\) van de data zijn groter dan of gelijk aan \\(x_p\\).\n\nAls twee aangrenzende uitkomsten aan de eisen voldoen, neemt men het gemiddelde van beide als kwantiel.\nHelaas stuit deze definitie op complicaties als je probeert de eigenlijk kwantielen te berekenen voor de waarnemingen in een dataset. Als je bijvoorbeeld het \\(Q(0,27)\\) kwantiel wilt berekenen uit 10 waarnemingen, dan is elke waarneming 10 procent van de hele set, dus je kunt een fractie van 0,2 of 0,3 van de gegevens afsplitsen, maar er is geen waarde die een fractie van precies 0,27 zal afsplitsen. En als je het splitsingspunt precies bij een waarneming zou plaatsen, zou je ook niet weten of je die waarneming in het onderste of bovenste deel moet meetellen.\nHet probleem is dus het berekenen van een kwantiel. Er zijn maar liefst 9 verschillende methodes, R-1 t/m R-9, zie wikipedia. R ondersteunt ze alle 9, maar Excel slechts twee ervan. Resultaten van softwarepaketten kunnen dus verschillen. Deze problematiek wordt fraai geschetst in Quantiles, Percentiles: Why so many ways to calculate them?.\nVoor gebruik in Excel zie ook Ranking Functions in Excel bij het onderdeel PERCENTILE.\nFormule methode R-1: Het \\(p\\)-kwantiel in een geordende verzameling van \\(n\\) elementen is het element met rangnummer \\(pn + 0,5\\)\nVoorbeeld 1\nDataset met 9 waarnemingen: 2, 3, 5, 7, 8, 9, 11, 12, 15\nHet 0,2-kwantiel is het getal 3. Er zijn 2, dus ten minste 1,8 getallen kleiner dan of gelijk aan 3 en er zijn 8, dus ten minste 7,2 getallen groter dan of gelijk aan 3.\nEn volgens methode 2\n\n0,2 kwantiel, 9*1/5 = 1,8 -> rangnummer 2. Dit is het getal 3\n0,4 kwantiel, 9*2/5 = 3,6 -> rangnummer 4. Dit is het getal 7\n0,6 kwantiel, 9*3/5 = 5,4 -> rangnummer 6. Dit is het getal 9\n0,8 kwantiel, 9*4/5 = 7,2 -> rangnummer 8. Dit is het getal 12\n\nZo heet het 0,25-kwantiel ook het \\(1^{ste}\\)-kwartiel en het \\(25^{ste}\\)-percentiel.\nVoorbeeld 2\nDataset met 10 waarnemingen: 2, 3, 5, 7, 8, 9, 11, 12, 15, 20\nVoor het 0,2-kwantiel voldoen zowel het getal 3 als 5. Hiervan wordt het gemiddelde genomen, dus 4.\nSpeciale kwantielen\n\n2 delen: mediaan\n4 delen: kwartielen\n10 delen: decielen\n100 delen: percentielen\n\nVoor het 0,2-kwantiel voldoen zowel het getal 3 als het getal 5. Het 0.2 kwantiel is hier het gemiddelde van, dus het getal 4.\n\n2.5.1 Kwantielen in Excel\nEr is een handige bruikbare definitie voor het berekenen van kwantielen. Er wordt uitgegaan van een verzameling geordende (van klein naar groot gesorteerd) gegevens \\(Y_i\\) met \\(i = 1,2,...n\\). Voor een fractie \\(p\\) (tussen 0 en 1) wordt het kwantiel \\(Q(p)\\) als volgt gedefinieerd. Neem voor \\(Q(p)\\) de waarde \\(Y_i\\) wanneer \\(p\\) een van de volgende fracties is \\(p_i = (i - 0,5)/n\\). Dus de kwantielen \\(Q(p_i)\\) van de waarnemingen zijn gelijk aan de geordende waarnemingen \\(Y_i\\) zelf.\n\n\n\n\n\n\nBelangrijk\n\n\n\nJe rekent dus niet voor een bepaalde fractie het bijbehorende kwantiel uit, maar je rekent voor elke kwantielwaarde (= de waarneming) de bijbehorende fractie uit.\n\n\nQ-Q plot\nEen Q-Q plot vergelijkt de kwantielen van een dataset met een set kwantielen van een theoretische kansverdeling. Daardoor is een Q-Q plot geschikt om te beoordelen of de verdeling van de dataset lijkt op die van de theoretische verdeling.\nDe werkwijze is als volgt\n\nBepaal voor elke waarneming (= kwantielwaarde) in de dataset de bijbehorende fractie.\nBereken voor elke gevonden fractie de bijbehorende kwantielwaarde van de theoretische verdeling uit.\nZet de kwantielwaarden tegen elkaar uit in een spreidingsdiagram.\nBeoordeel of de punten op een rechte lijn liggen. Hoe beter de punten samenvallen met de rechte lijn, des te meer lijkt de verdeling in de dataset op de theoretische verdeling.\n\nVoorbeeld\nIn de volgende figuur staan 22 waarnemingen \\(Y_i\\) (zie Excelbestand qqplot.xlsx. Voor elke waarneming is de bijbehorende fractie \\(p_i\\) berekend. Voor B2 is de formule =(A2-0,5)/22 welke vervolgens naar beneden gekopieerd is. Daarna is voor elke fractie de bijbehorende waarde in de standaard normale verdeling bepaald. De formule in D2 is =NORM.S.INV(B2) welke weer naar beneden gekopieerd is. Maak vervolgens een spreidingsdiagram waarbij je originele waarnemingen langs de horizontale as plaatst en de waarde uit de normale verdeling langs de verticale as. Breng ook een lineaire trendlijn aan.\n\n\n\n\n\nFiguur 2.13: QQ plot voor een serie van 22 waarnemingen.\n\n\n\n\nDe punten liggen redelijk op een rechte lijn zodat er vanuit gegaan kan worden dat de waarnemingen redelijk een normale verdeling volgen."
  },
  {
    "objectID": "kansverdelingen.html#verd-symmetrie",
    "href": "kansverdelingen.html#verd-symmetrie",
    "title": "2  Kansverdelingen",
    "section": "2.6 Scheefheid en Kurtosis",
    "text": "2.6 Scheefheid en Kurtosis\nScheefheid en kurtosis zijn twee belangrijke maatstaven in de statistieken. Scheefheid verwijst naar het gebrek aan symmetrie en kurtosis verwijst naar de piek van een verdeling.\n\n2.6.1 Scheefheid\nKenmerken van een scheve verdeling zijn:\n\nGemiddelde, mediaan en modus vallen op verschillende punten.\nKwartielen liggen niet op gelijke afstand van de mediaan.\nDe curve is niet symmetrisch zoals bij een normale verdeling, maar meer naar de ene kant uitgerekt dan naar de andere, heeft een staart.\n\nBij een frequentieverdeling kun je drie vormen van de curve aantreffen.\n\nSymmetrische verdeling\nRechts scheve verdeling - Heeft een lange rechterstaart, wat duidt op extreme waarden aan de positieve kant van de verdeling.\nLinks scheve verdeling - Heeft een lange linkerstaart, wat duidt op extreme waarden aan de negatieve kant van de verdeling.\n\nVoorbeelden rechts scheef\n\nDe verdeling van individuele inkomens is meestal rechts scheef, waarbij de meeste personen minder dan het gemiddelde verdienen, maar met een lange rechterstaart van personen die veel meer verdienen.\nDe verdeling van de scores op een bijzonder moeilijk examen zal positief scheef zijn, waarbij de meeste studenten rond een bepaalde gemiddelde waarde scoren en een paar uitschieters die veel hoger scoren.\nDe verdeling van de familiegrootte is waarschijnlijk rechts scheef, omdat de meeste families 0-2 kinderen hebben, maar er zijn uitschieters met veel meer kinderen.\nDe verdeling van de verkochte tickets per film is rechts scheef, omdat de meeste films matig zijn en relatief weinig totale kaartjes verkopen. Sommige toppertjes verkopen echter zeer veel kaartjes, waardoor de verdeling van bioscoopkaartjes rechts scheef loopt.\n\nVoorbeelden links scheef\n\nDe verdeling van de leeftijd van overlijden in de meeste populaties is links scheef. De meeste mensen worden tussen de 70 en 80 jaar oud, slechts weinig mensen worden veel ouder.\nDe verdeling van scores op gemakkelijke examens of toetsen is vaak negatief scheef omdat de meeste studenten erg hoog scoren, terwijl een paar studenten veel lager scoren dan het gemiddelde.\nIn de meeste jaren is de verdeling van de lengtes van het verspringen voor deelnemers aan de Olympische Spelen negatief, omdat de meeste deelnemers een sprong maken van ongeveer 7,5-8 meter, terwijl enkelen een sprong maken van slechts 5-6 meter.\nDe verdeling van de dagelijkse beursrendementen is negatief scheef omdat de aandelenmarkt op de meeste dagen een licht positief rendement oplevert, maar af en toe enorme negatieve rendementen op een paar dagen.\n\nEen beta verdeling kun je goed gebruiken om scheve verdelingen te demonstreren. Het aantal waarden moet je wel voldoende groot nemen, want zowel scheefheid en kurtosis hangen hier behoorlijk vanaf.\n\n\\(\\alpha\\) > \\(\\beta\\) : Links scheve verdeling (staart links)\n\\(\\alpha\\) < \\(\\beta\\) : Rechts scheve verdeling (staart rechts)\n\n\n# definieer reeks\nx <- seq(0, 1, length = 100)\n# parameters beta verdeling\nalpha <- 5\nbeta <- 2\n# maak grafiek\npar(bg = \"transparent\")\nplot(x, dbeta(x, alpha, alpha), type = \"l\", ylab = \"dichtheid\", col = \"green\")\nlines(x, dbeta(x, beta, alpha), col = \"blue\")\nlines(x, dbeta(x, alpha, beta), col = \"red\")\n\n\n\n\nFiguur 2.14: Beta verdeling: rechts scheef (blauw), links scheef (rood) en normaal (groen).\n\n\n\n\nEen andere benadering is door willekeurige waarden uit een betaverdeling te genereren.\n\naantal <- 10000\nset.seed(35486)\nxl <- rbeta(aantal, alpha, beta) # links scheef\nxr <- rbeta(aantal, beta, alpha) # rechts scheef\nxs <- rbeta(aantal, alpha, alpha) # symmetrisch\npar(bg = \"transparent\")\nplot(density(xs), col = \"green\", xlim = c(- 0.1, 1.1), ylim = c(0, 5),\n     main=\"Scheefheid\", ylab = \"\", xlab = \"\", xaxt=\"n\", yaxt=\"n\", frame.plot=FALSE)\nlines(density(xl), col = \"red\")\nlines(density(xr), col = \"blue\")\nlegend(\"topleft\",\n       legend = c(\"rechts scheef\", \"symmetrisch\", \"links scheef\"),\n       col = c(\"blue\", \"green\", \"red\"),\n       lty = 1,\n       cex = 0.8)\n\n\n\n\nFiguur 2.15: gegernereerde waarden uit een Beta verdeling.\n\n\n\n\nGecombineerd met een histogram.\n\nhist(xl, probability = TRUE, xlim = c(min(xl), max(xl)), \n     main = \"\", xlab = \"x\", ylab = \"Dichtheid\")\nlines(density(xl), col = \"red\", lwd = 2)\n\nhist(xr, probability = TRUE, xlim = c(min(xr), max(xr)), \n     main = \"\", xlab = \"x\")\nlines(density(xr), col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n(a) Links scheef\n\n\n\n\n\n\n\n(b) Rechts scheef\n\n\n\n\nFiguur 2.16: Dichtheid met histogram voor scheve verdelingen.\n\n\n\nggplot\n\ndf <- data.frame(xl, xr, xs)\n\nggplot(data = df, aes(xr)) + \n  geom_density() + theme_classic() + xlab(\"x\") + ylab(\"dichtheid\")\nggplot(data = df, aes(xs)) + \n  geom_density() + theme_classic() + xlab(\"x\") + ylab(\"dichtheid\")\nggplot(data = df, aes(xl)) + \n  geom_density() + theme_classic() + xlab(\"x\") + ylab(\"dichtheid\")\n\n\n\n\n\n\n\n(a) Rechts scheef\n\n\n\n\n\n\n\n(b) Symmetrisch\n\n\n\n\n\n\n\n(c) Links scheef\n\n\n\n\nFiguur 2.17: Vergelijking verdelingen.\n\n\n\nBerekening scheefheid\nEen manier om de scheefheid in een dataset te berekenen is met Pearson’s scheefheid coefficient welke op twee manieren bepaald kan worden:\n\n\\(scheefheid = \\frac{gemiddelde - modus}{standaarddeviatie}\\)\n\\(scheefheid = 3 *\\frac{gemiddelde - mediaan}{standaarddeviatie}\\) heeft de voorkeur\n\nStandaard R heeft geen functie voor de berekening van de scheefheid en kurtosis. De packages e1071 en moments hebben beide een functie skewness() en kurtosis().\n\n\n2.6.2 Kurtosis\nKurtosis is een statistische maatstaf die aangeeft in welke mate de data zich in de staarten of de piek van een verdeling bevinden, vergeleken met een normale verdeling. Met andere woorden, het geeft aan of de staart van de verdeling verder reikt dan de ±3 standaarddeviatie van het gemiddelde of niet.\nEr zijn drie soorten kurtosis die je in een verdeling kunt aantreffen:\n\nMesokurtic - \\(Kurtosis \\pm3\\). Verdeling heeft de vorm van een normale verdeling.\nLeptokurtiv - \\(Kurtosis \\gt 3\\). Verdeling heeft een scherpere piek en zwaardere staarten, wat wijst op meer uitbijters en minder waarden in de buurt van het gemiddelde.\nPlatykurtic - \\(Kurtosis \\lt 3\\). Is minder gepiekt en heeft dunnere staarten, wat wijst op minder uitbijters en meer waarden in de buurt van het gemiddelde.\n\n\\[Kurtosis = \\frac{n * \\sum_i^n (x_i - \\bar{x})^4}{(\\sum_i^n (x_i - \\bar{x})^2)^2}\\]\nBij data-analyse is het concept van kurtosis erg belangrijk omdat het aangeeft hoe de uitbijters over de verdeling zijn verdeeld in vergelijking met een normale verdeling. Soms wordt de relatieve kurtosis van de verdeling bepaald in termen van overtollige kurtosis, welke berekend wordt door 3 af te trekken van de kurtosis, dus \\(kurtosis - 3\\). Je kunt dan de kurtosis uitdrukken als positief, negatief of nul.\n\n\n\n\n\n\nVoorbeeld\n\n\n\nIn de financiele wereld wordt op het gebied van risicobeheer en beleggingsrendement vaak gekeken naar de kurtosis. Deze geeft aan of er enige kans is op extreme waarden van rendementen. Een belegger zal zich vaak meer op zijn gemak voelen bij een platykurtische rendementsverdeling, omdat dit stabiele rendementen en een lager risico op plotselinge schokken van uitschieters aangeeft, terwijl een leptokurtische verdeling meer kansen op een hoger rendement maar met een hoger risico oplevert.\n\n\n\n\n2.6.3 Oefeningen\nSymmetrische verdeling\n\nx <- rep(seq(from=65, to=135, by=5), \n         times=c(seq(3, 24, 3), seq(21,3,-3)))\nhist(x, breaks = seq(from=60, to=140, by=5), prob = TRUE, \n     main = \"Symmetrische verdeling\", ylab = \"Dichtheid\",\n     col = \"lightblue\")\nlines(density(x), col = \"black\", lwd = 2)\n\n\n\n\nFiguur 2.18: Symmetrische verdeling.\n\n\n\n\nScheefheid = 0 en Kurtosis = 2.381\nPositieve scheefheid\n\nx <- rep(seq(from=90, to=140, by=5), \n         times = c(18,21,24,21,18,15,12,9,6,3,1))\nhist(x, breaks = seq(from=80, to=150, by=5), prob = TRUE, \n     main = \"Scheefheid positief\",  ylab = \"Dichtheid\",\n     col = \"lightblue\")\nlines(density(x), col = \"black\", lwd = 2)\n\n\n\n\nFiguur 2.19: Positieve scheefheid.\n\n\n\n\nScheefheid = 0.509 en Kurtosis = 2.45\nNegatieve scheefheid\n\nx <- rep(seq(from=60, to=110, by=5), \n         times = c(1,3,6,9,12,15,18,21,24,21,18))\nhist(x, breaks = seq(from=50, to=120, by=5), prob = TRUE, \n     main = \"Scheefheid negatief\",  ylab = \"Dichtheid\",\n     col = \"lightblue\")\nlines(density(x), col = \"black\", lwd = 2)\n\n\n\n\nFiguur 2.20: Negatieve scheefheid.\n\n\n\n\nScheefheid = -0.509 en Kurtosis = 2.45\nKurtosis negatief\n\nx <- rep(seq(from=65, to=135, by=5), \n         each = 10)\nhist(x, breaks = seq(from=60, to=140, by=5), prob = TRUE, \n     main = \"Kurtosis negatief\",  ylab = \"Dichtheid\",\n     col = \"lightblue\")\nlines(density(x), col = \"black\", lwd = 2)\n\n\n\n\nFiguur 2.21: Negatieve kurtosis\n\n\n\n\nKurtosis = 1.789\nKurtosis positief\n\nx <- rep(seq(from=65, to=135, by=5), \n         times = c(2,2,3,3,3,4,27,32,27,4,3,3,3,2,2))\nhist(x, breaks = seq(from=60, to=140, by=5), prob = TRUE, \n     main = \"Kurtosis positief\",  ylab = \"Dichtheid\",\n     col = \"lightblue\")\nlines(density(x), col = \"black\", lwd = 2)\n\n\n\n\nFiguur 2.22: Positieve kurtosis\n\n\n\n\nKurtosis = 4.722\nVoorbeeld\n\nxn <- rep(seq(from=65, to=135, by=5), \n          times = c(3,4,4,4,5,5,5,5,5,5,5,4,4,4,3))\nplot(density(xn), main=\"\", xlab=\"\", ylab=\"\", yaxt = \"n\", xaxt = \"n\")\n\nxp <- rep(seq(from=65, to=135, by=5), \n          times = c(2,2,3,3,3,4,27,32,27,4,3,3,3,2,2))\nplot(density(xp), main = \"\", xlab=\"\", ylab=\"\", yaxt = \"n\", xaxt = \"n\")\n\n\n\n\n\n\n\n(a) Negatieve kurtosis\n\n\n\n\n\n\n\n(b) Positieve kurtosis\n\n\n\n\nFiguur 2.23: Dichtheidsdiagram voor verdelingen met een negatieve en positieve kurtosis."
  },
  {
    "objectID": "kansverdelingen.html#sec-verd-fitdistr",
    "href": "kansverdelingen.html#sec-verd-fitdistr",
    "title": "2  Kansverdelingen",
    "section": "2.7 Geschikte verdeling zoeken",
    "text": "2.7 Geschikte verdeling zoeken\nEen interessante functie is fitdistr() uit package MASS waarmee je een geschikte kansverdeling voor een dataset kunt bepalen..\nfitdistr(x, densfun, start, ...)\n\nx - numerieke vector met de te onderzoeken waarden\ndensfun - String met verdeling waarmee getest wordt: “beta”, “cauchy”, “chi-squared”, “exponential”, “gamma”, “geometric”, “log-normal”, “lognormal”, “logistic”, “negative binomial”, “normal”, “Poisson”, “t”, “weibull”\nstart - optioneel beginwaarden voor parameters\n\nReturnwaarden\n\nestimate - de schatting van de parameters\nsd - de geschatte standaardfouten\nvcov - de geschatte variantie-covariantie matrix\nloglik - de log-likelihood.\n\n\n# Genereer een normale verdeling\nx <- rnorm(n = 1000, mean = 6, sd = 1.5)\n\n# Geschatte parameters\nverdeling <- MASS::fitdistr(x, \"normal\")\nverdeling$estimate\n#> mean   sd \n#> 5.97 1.50\nverdeling$sd\n#>   mean     sd \n#> 0.0474 0.0335\nverdeling$vcov\n#>         mean      sd\n#> mean 0.00225 0.00000\n#> sd   0.00000 0.00112\nverdeling$loglik\n#> [1] -1824\n\nBronnen:\n\nFitting distributions with r"
  },
  {
    "objectID": "variabelen.html#sec-var-soort",
    "href": "variabelen.html#sec-var-soort",
    "title": "3  Variabelen",
    "section": "3.1 Soorten variabelen",
    "text": "3.1 Soorten variabelen\n\nkwantitatieve variabele\n\nwordt numeriek gemeten\nrekenkundige bewerkingen zijn mogelijk\ncontinu of discreet\n\nkwalitatieve variabele\n\nwordt niet numeriek gemeten, elke waarde heet ook wel categorie\ngeen rekenkundige bewerkingen, wel aantallen tellen per categorie"
  },
  {
    "objectID": "variabelen.html#sec-var-meetniveau",
    "href": "variabelen.html#sec-var-meetniveau",
    "title": "3  Variabelen",
    "section": "3.2 Meetniveaus (schalen)",
    "text": "3.2 Meetniveaus (schalen)\nIn de statistiek worden variabelen meestal in 4 meetniveaus (schalen) ingedeeld: Nominaal, Ordinaal, Interval en Ratio. het meetniveau van een variabele is van belang voor wat je er mee mag doen.\n\nNominaal\nDe gegevens zijn kwalitatief of beschrijvend. Voorbeelden: geslacht, nationaliteit, godsdienst, woonplaats, burgerlijke staat. De waarden van de variabelen worden ook wel categorien genoemd. Ze hebben alleen verschillende namen (naam in het Latijn is nomen), getalswaarden hebben geen betekenis als numerieke waarde (je kunt er niet mee rekenen). De waarden hebben geen logische volgorde. Voorbeelden: postcode, geslacht, nationaliteit, godsdienst, …\n\n\nOrdinaal\nDe gegevens zijn kwalitatief en hebben een logische volgorde, een bepaalde ordening. Voorbeelden: restaurantclassificatie (aantal sterren), enqu?tevragen (Likertschalen: 1=zeer goed, 2=goed, …), plaats in wedstrijduitslag (1, 2, 3, …). De waarden van de variabelen hebben wel een logische volgorde, je kunt ze bijvoorbeeld sorteren van groot naar klein. Met de waarden kun je geen rekenkundige bewerkingen uitvoeren. En uit de grootte van de verschillen kun je geen conclusies trekken, bijvoorbeeld 2 sterren is twee keer zo goed als 1 ster.\n\n\nInterval\nDe gegevens zijn kwantitatief, maar hebben geen natuurlijk nulpunt, de keuze van een nulpunt is arbitrair. Het verschil tussen de waarden heeft wel betekenis. Voorbeelden: kloktijd, Celsius temperatuur. Het verschil tussen 7:00 uur en 9: uur is even groot als het verschil tussen 15:00 uur en 17:00 uur. Je kunt echter niet zeggen Om 4 uur is het twee keer zo laat als om 2 uur, 24oC is 2 keer zo warm als 12oC. Wel is het verschil tussen de waarden van belang en significant. Sommige rekenkundige bewerkingen kun je wel uitvoeren zoals, optellen, aftrekken, gemiddelde bepalen. Voorbeelden: datum, jaartal, temperatuur (C en F), …\n\n\nRatio\nDe gegevens zijn kwantitatief en hebben een natuurlijk nulpunt. Voorbeelden: inkomen, uitgaven, gewicht, lengte. Een ratiovariabele meet dus de omvang van de variabele. Allerlei rekenkundige bewerkingen kunnen worden toegepast. Voorbeelden: lengte, massa, snelheid, temperatuur (K) …"
  },
  {
    "objectID": "variabelen.html#sec-var-bewerkingen",
    "href": "variabelen.html#sec-var-bewerkingen",
    "title": "3  Variabelen",
    "section": "3.3 Statistische bewerkingen",
    "text": "3.3 Statistische bewerkingen\n\nNominaal: modus, frequentie, chikwadraat, cluster analyse\nOrdinaal: mediaan, Kruskal-Wallis, rangorde correlatie, non-parametrische toetsen\nInterval: rekenkundig gemiddelde, correlatie, regressie, anova (soms), factor analyse, sommige parametrische toetsen\nRatio: geometrisch en harmonisch gemiddelde, anova, regressie, correlatiecoefficient\n\nR-Functies beschrijvende statistiek\n\n\n\nFunctie\nToelichting\n\n\n\n\nmean(x)\ngemiddelde\n\n\nsd(x)\nstandaarddeviatie\n\n\nvar(x)\nvariantie\n\n\nmedian(x)\nmediaan\n\n\nIQR(x)\nInterkwartiel reeks\n\n\nquantile(x)\nkwartiel\n\n\nsummary(x)\nsamenvatting (minimum, maximum, median, Q1, Q3)\n\n\ntable(x)\nFrequentietabel"
  },
  {
    "objectID": "variabelen.html#sec-var-r",
    "href": "variabelen.html#sec-var-r",
    "title": "3  Variabelen",
    "section": "3.4 R variabelen en gegevenstypes",
    "text": "3.4 R variabelen en gegevenstypes\nIn de praktijk wordt meer met gegevenstypes gewerkt dan met meetniveaus. De belangrijkste types waarmee gewerkt wordt zijn:\n\nnumeriek\ncomplex\ninteger\nlogical\ncharacter\n\nTypes variabelen in R\nDe voorgaande gegevenstypes kunnen opgeslagen worden in verschillende types variabelen in R. De belangrijkste zijn:\n\nvector\nfactor\narray\nmatrix\nlist\ndata.frame\ntibble\n\nDaarnaast nog:\n\nDate/Time, afhankelijk van hoe gemeten wordt kunnen deze zowel discreet als continu zijn. Deze variabelen worden als een apart gegevenstype behandeld. Brengt complicaties mee in de vorm van schrikkeljaren en tijdzones. Het gegevenstype van een variabele kan opgevraagd worden met de functie class()."
  },
  {
    "objectID": "toetsen.html#sec-toetsen-hypothesen",
    "href": "toetsen.html#sec-toetsen-hypothesen",
    "title": "4  Toetsen",
    "section": "4.1 Hypothesen",
    "text": "4.1 Hypothesen\nIn de statistische toetsingstheorie worden hypothesen (veronderstellingen) gemaakt over de kansverdeling van de kansvariabele. Het doel van een statistische toets is: door middel van een steekproef een of ander effect aan te tonen. De gevolgde methode is dat aangenomen wordt dat het effect niet bestaat. Dit wordt de nulhypothese genoemd, aangeduid met \\(H_0\\). Op basis van de gevonden resultaten wordt bekeken of deze veronderstelling stand kan houden.\nAls alternatieve hypothese, aangeduid met \\(H_1\\), ga je uit van de veronderstelling dat het gezochte effect wel bestaat. Het is deze alternatieve hypothese die men tracht te “bewijzen”. Hoewel de alternatieve hypothese vaak het complement is van de nulhypothese (en dan eigenlijk overbodig), hoeft dit niet noodzakelijkerwijs het geval te zijn."
  },
  {
    "objectID": "toetsen.html#sec-toetsen-toetsingsgrootheid",
    "href": "toetsen.html#sec-toetsen-toetsingsgrootheid",
    "title": "4  Toetsen",
    "section": "4.2 Toetsingsgrootheid",
    "text": "4.2 Toetsingsgrootheid\nNa het formuleren van de hypothesen formuleer je een toetsingsgrootheid. Deze moet de informatie uit de steekproef samenvatten in een getal dat als maatstaf kan functioneren om de nulhypothese al dan niet te verwerpen. Veel gebruikte toetsingsgrootheden zijn: (steekproef)gemiddelde, (steekproef)fractie en (steekproef)variantie."
  },
  {
    "objectID": "toetsen.html#sec-toetsen-kansverdeling",
    "href": "toetsen.html#sec-toetsen-kansverdeling",
    "title": "4  Toetsen",
    "section": "4.3 Kansverdeling toetsingsgrootheid onder \\(H_0\\)",
    "text": "4.3 Kansverdeling toetsingsgrootheid onder \\(H_0\\)\nDoor uit te gaan van de nulhypothese is het mogelijk om een kansverdeling van de te onderzoeken variabele op te stellen. Hierdoor kun je uitspraken doen over de mogelijke waarden van de steekproefresultaten."
  },
  {
    "objectID": "toetsen.html#sec-toetsen-steekproefuitkomst",
    "href": "toetsen.html#sec-toetsen-steekproefuitkomst",
    "title": "4  Toetsen",
    "section": "4.4 Steekproefuitkomst",
    "text": "4.4 Steekproefuitkomst\nBereken de waarde van de toetsingsgrootheid uit de steekproefresultaten"
  },
  {
    "objectID": "toetsen.html#sec-toetsen-kritiekgebied",
    "href": "toetsen.html#sec-toetsen-kritiekgebied",
    "title": "4  Toetsen",
    "section": "4.5 Kritiek gebied",
    "text": "4.5 Kritiek gebied\nHet gaat er nu om dat voor de toetsingsgrootheid aangegeven wordt welke waarden als aannemelijk beschouwd kunnen worden en welke waarden als uitzonderlijk, gegeven \\(H_0\\). Als de steekproef een uitzonderlijke uitkomst oplevert, dan wijst dat er op dat de geldigheid van \\(H_0\\) in twijfel moet worden getrokken. Dan wordt \\(H_0\\) verworpen ten gunste van \\(H_1\\). De verzameling uitkomsten kunnen in twee gebieden verdeeld worden:\n\nAcceptatiegebied, de uitkomsten die niet leiden toe verwerping van \\(H_0\\).\nKritieke gebied Z, de uitkomsten die leiden tot verwerping van \\(H_0\\).\n\nAls criterium om tot een dergelijke verdeling te komen wordt de kans genomen dat de nulhypothese ten onrechte verworpen wordt. Dit wordt ook wel de onbetrouwbaarheid of fout van de eerste soort genoemd en aangeduid met \\(\\alpha\\). De waarde van \\(\\alpha\\) wordt meestal vooraf gekozen.\n\n\n\n\n\n\nOpmerking\n\n\n\nHet kritieke gebied volgt uit de kansverdeling van de toetsingsgrootheid en kan dus bepaald worden zonder over steekproefresultaten te beschikken. het steekproefresultaat wordt in feite achteraf vergeleken met het kritieke gebied."
  },
  {
    "objectID": "toetsen.html#sec-toetsen-pwaarde",
    "href": "toetsen.html#sec-toetsen-pwaarde",
    "title": "4  Toetsen",
    "section": "4.6 p-waarde",
    "text": "4.6 p-waarde\nAls alternatief voor de bepaling van het kritieke gebied kan ook de overschrijdingskans bepaald worden van de gevonden waarde van de toetsingsgrootheid. Deze overschrijdingskans wordt meestal de p-waarde genoemd. Hoe kleiner de p-waarde, des te extremer de uitkomst.\n\n\n\n\n\n\nOpmerking\n\n\n\nOm de p-waarde te bepalen moet je over de steekproefresultaten beschikken."
  },
  {
    "objectID": "toetsen.html#sec-toetsen-spa",
    "href": "toetsen.html#sec-toetsen-spa",
    "title": "4  Toetsen",
    "section": "4.7 Systematische Probleem Aanpak (SPA)",
    "text": "4.7 Systematische Probleem Aanpak (SPA)\n\nFormuleer \\(H_0\\) en \\(H_1\\) (let op de één/twee-zijdigheid!)\nKies de onbetrouwbaarheid (\\(\\alpha\\))\nFormuleer de toetsingsgrootheid (op grond van de waarde van welke variabele wordt een besluit genomen?)\nBepaal de kansverdeling van de toetsingsgrootheid onder de aanname dat \\(H_0\\) waar is.!\nMethode 1\n\nBepaal het kritieke gebied. Dit zijn de verzameling uitkomsten die leiden tot verwerping van \\(H_0\\).\nKijk of de waarde van de toetsingsgrootheid in de steekproef wel/niet kritiek is.\n\nMethode 2\n\nBereken de overschrijdingskans (p-waarde) bij de steekproefwaarde van de toetsingsgrootheid.\nWanneer de p-waarde minder is dan \\(\\alpha\\) (bij een éénzijdige toets) of \\(\\frac{1}{2} \\alpha\\) (bij een tweezijdige toets) wordt \\(H_0\\) verworpen.\n\nBeslis welke hypothese wordt aanvaard en vertaal de beslissing terug naar de werkelijkheid.\n\n\n\n\n\n\n\nTip\n\n\n\nHet is aan te raden om een schets van de verdeling te maken en hierin \\(\\alpha\\) en het kritieke gebied en/of p-waarde aan te geven."
  },
  {
    "objectID": "toetsen.html#sec-toetsen-soorten",
    "href": "toetsen.html#sec-toetsen-soorten",
    "title": "4  Toetsen",
    "section": "4.8 Soorten statistische toetsen",
    "text": "4.8 Soorten statistische toetsen\nOm te bepalen welke toets je het beste kunt gebruiken moet je het volgende weten:\n\nHet aantal variabelen (één, twee of meer) waarmee je een analyse wilt uitvoeren\nHet meetniveau of gegevenstype van de te onderzoeken variabelen\nZijn de waarnemingen onafhankelijk of gepaard.\n\n\n4.8.1 Verschiltoetsen\nVerschil van één kenmerk tussen twee groepen\nHierbij onderzoek je of één bepaald kenmerk verschillend is voor twee groepen. Bijvoorbeeld een onderzoek naar het verschil in de gemiddelde lengte bij mannen en vrouwen. De waarnemingen zijn dan onafhankelijk.\n\n\n\nafhankelijke variabele\ntoets\n\n\n\n\nnominaal\nchikwadraat\n\n\nordinaal\nMann-Whitney\n\n\ninterval/ratio\nt\n\n\n\nVerschil tussen twee kenmerken binnen één groep\nBijvoorbeeld of er binnen een bepaalde groep personen verschil is tussen de linker schoenmaat en de rechter schoenmaat. De waarnemingen zijn dan gepaard.\n\n\n\nvariabelen\ntoets\n\n\n\n\nnominaal\nchikwadraat\n\n\nordinaal\nWilcoxon\n\n\ninterval/ratio\nt\n\n\n\n\n\n4.8.2 Samenhang tussen twee kenmerken\nBijvoorbeeld of bij een groep studenten de hoogte van het behaalde cijfer voor een tentamen afhangt van het aantal uren studietijd.\n\n\n\nvariabele 1 / 2\nordinaal\ninterval/ratio\n\n\n\n\nordinaal\nSpearman rang\n\n\n\ninterval/ratio\n\nPearson product"
  },
  {
    "objectID": "toetsen.html#sec-toetsen-oefeningen",
    "href": "toetsen.html#sec-toetsen-oefeningen",
    "title": "4  Toetsen",
    "section": "4.9 Oefeningen",
    "text": "4.9 Oefeningen\n\nOefening 4.1 Muntstuk\n(Bron: boek Buijs, hfst. 9, voorbeeld 1a, 2a, 4)\nVan een munstuk moet gecontroleerd worden of deze ‘zuiver’ is. Voor deze controle worden 100 worpen met dit muntstuk uitgevoerd. Er verschijnt 64 keer kop boven. Is deze munt zuiver?\nDe hypothesen worden als volgt geformuleerd:\n\\(H_0: P(kop) = \\pi = \\frac{1}{2}\\) (munt is zuiver)\n\\(H_1: P(kop) = \\pi \\neq \\frac{1}{2}\\) (Dit is dus een tweezijdige toetsing)\nToetsingsgrootheid \\(k\\): het aantal keren ‘kop’\nDe kansvariabele \\(\\underline{k} \\sim Bin(n=100 , \\pi = \\frac{1}{2})\\)\nHet kritieke gebied is tweezijdig, aan beide kanten een gebied van 2.5%. We zoeken twee grenswaarden L(inks) en R(echts) waarvoor geldt:\n\\(P(\\underline{k} \\lt L) \\lt 0.025\\) en \\(P(\\underline{k} \\gt R) \\lt 0.025\\) en \\(P(L \\le \\underline{k} \\le R) \\ge 0.975\\)\n\nqbinom(0.025, 100, 0.5)\n\n[1] 40\n\npbinom(40, 100, 0.5)\n\n[1] 0.02844397\n\npbinom(39, 100, 0.5)\n\n[1] 0.0176001\n\nqbinom(0.975, 100, 0.5)\n\n[1] 60\n\npbinom(60, 100, 0.5)\n\n[1] 0.9823999\n\npbinom(59, 100, 0.5)\n\n[1] 0.971556\n\n\nkritiek gebied\nHet kritieke gebied: \\(Z = \\{ k \\mid k \\le 39 \\: of \\: k \\ge 60 \\}\\)\nDe gevonden waarde bedraagt 64, deze ligt in \\(Z\\), dus \\(H_0\\) verwerpen, het gebruikte muntstuk is niet zuiver.\n\n#Grafiek tekenen\nx <- seq(0, 100, by = 1)\ny <- dbinom(x, 100, 0.5)\nplot(x, y, type = \"l\")\nabline(v = 60)\nabline(v = 39)\n\n\n\n\n\n\nOefening 4.2 Productieproces\n(Bron: boek Buijs, hfst. 9, voorbeeld 1b, 2b, 5)\nVolgens een fabrikant levert zijn productieproces hoogstens 20% exemplaren van mindere kwaliteit op. Bij een steekproef worden 20 exemplaren gecontroleerd waarvan er 6 van mindere kwaliteit zijn.\nDe hypothesen worden als volgt geformuleerd:\n\\(H_0: \\pi \\le 0.20\\)\n\\(H_1: \\pi \\gt 0.20\\) (Dit is dus een rechts eenzijdige toetsing)\nToetsingsgrootheid \\(k\\): het aantal exemplaren van mindere kwaliteit\nDe kansvariabele \\(k \\sim Bin(n=20 , \\pi = 0.20)\\)\nkritiek gebied\nWe zoeken nu de grenswaarde G waarvoor geldt \\(P(k \\le G) \\ge 0.95\\) en \\(P(k \\gt G) \\lt 0.05\\)\n\nqbinom(0.95, 20, 0.2)\n\n[1] 7\n\npbinom(7, 20, 0.2)\n\n[1] 0.9678573\n\n\nDe grenswaarde \\(c = 7\\), dus het kritieke gebied: \\(Z = \\{ k \\mid k \\ge 8 \\}\\)\nHet gevonden aantal 6 zit niet in het kritieke gebied, \\(H_0\\) wordt niet verworpen, de fabrikant kan gelijk hebben.\n\n\nOefening 4.3 Productgewicht\n(Bron: boek Buijs, hfst. 9, voorbeeld 1c, 2c, 3, 9)\nEen fabrikant garandeert dat het afgeleverde gewicht van een product minstens 1000 gram per verpakking bedraagt. Bij een steekproef worden 100 verpakkingen onderzocht, waarvan het gemiddelde gewicht 996.5 gram is. Ga er van uit dat het verpakkingsgewicht normaal verdeeld is met \\(\\sigma = 25\\). Onderzoek de bewering van de fabrikant met \\(\\alpha = 0.01\\)\nDe hypothesen worden als volgt geformuleerd:\n\\(H_0: \\mu \\ge 1000\\)\n\\(H_1: \\mu \\lt 1000\\) (Dit is dus een links eenzijdige toetsing)\nToetsingsgrootheid \\(\\bar{x}\\) : het steekproefgemiddelde\nDe kansvariabele \\(\\bar{x} \\sim N(\\mu = 1000 , \\sigma = \\frac{25}{\\sqrt{100}} = 2.5)\\)\nWe zoeken nu de grenswaarde c waarvoor geldt \\(P(\\bar{x} < c) \\lt 0.01\\)\n\nqnorm(0.01, 1000, 2.5)\n\n[1] 994.1841\n\n\nkritiek gebied\nHet kritieke gebied: \\(Z = \\{ \\bar{x} \\mid \\bar{x} \\lt 994.1841 \\}\\)\nHet gevonden steekproefgemiddelde is 996.5, deze ligt niet in \\(Z\\), dus \\(H_0\\) wordt niet verworpen, dus de fabrikant kan gelijk hebben.\np-waarde\nBereken de overschrijdingskans van het gevonden gemiddelde 996.5.\n\npnorm(996.5, mean = 1000, sd = 2.5)\n\n[1] 0.08075666\n\n\nDe overschrijdingskans is groter dan 0.01 dus wordt \\(H_0\\) niet verworpen.\n\n\nOefening 4.4 Montagetijden\n(Bron: boek Buijs, hfst. 9, voorbeeld 6, 8)\nDe montagetijden zijn normaal verdeeld met \\(\\mu\\) = 300 sec en \\(\\sigma\\) = 15 sec. Bij een steekproef van 25 waarnemingen werd een gemiddelde montagetijd van 292 sec. gevonden. Wijkt deze significant af van de verdeling? Toets met \\(\\alpha\\) = 0.05.\nDe hypothesen worden als volgt geformuleerd:\n\\(H_0: \\mu = 300\\)\n\\(H_1: \\mu \\neq 300\\) (Dit is dus een tweezijdige toetsing)\nToetsingsgrootheid \\(\\bar{x}\\) : het steekproefgemiddelde\nDe kansvariabele \\(\\bar{x} \\sim N(\\mu = 300 , \\sigma = \\frac{15}{\\sqrt{25}} = 3)\\)\nkritiek gebied\nHet kritieke gebied is tweezijdig, aan beide kanten een gebied van 2.5%. We zoeken twee grenswaarden L en R waarvoor geldt:\n\\(P(\\bar{x} \\lt L) \\lt 0.025\\) en \\(P(\\bar{x} \\gt R) \\lt 0.025\\) en \\(P(L \\le \\bar{x} \\le R) \\ge 0.975\\)\n\nqnorm(0.025, 300, 3)\n\n[1] 294.1201\n\nqnorm(0.975, 300, 3)\n\n[1] 305.8799\n\n\nKritieke gebied: \\(Z = \\{ \\bar{x} \\mid \\bar{x} \\le 294.12 \\: of \\: \\bar{x} \\ge 305.8799 \\}\\)\nHet gevonden steekproefgemiddelde is 292, deze ligt in Z, dus \\(H_0\\) wordt verworpen, dus de gemiddelde montagetijd wijkt af van \\(\\mu\\) = 300 sec.\n\n\nOefening 4.5 Geneesmiddel\n(Bron: boek Buijs, hfst. 9, voorbeeld 7)\nEen geneesmiddel zou in 99% van de gevallen doeltreffend zijn. Bij een steekproef van 200 proefpersonen was het in 8 gevallen geen succes. Toets of de fabrikant gelijk kan hebben met \\(\\alpha\\) = 0.01.\nMinstens 99% succesvol kan ook geformuleerd worden als hoogstens 1% niet werkzaam.\nDe hypothesen worden als volgt geformuleerd (\\(\\pi\\) is de kans op een mislukking:\n\\(H_0: \\pi \\le 0.01\\)\n\\(H_1: \\pi \\gt 0.01\\) (Dit is dus een rechts eenzijdige toetsing)\nToetsingsgrootheid \\(\\underline{k}\\): het aantal mislukkingen\nDe kansvariabele \\(\\underline{k} \\sim Bin(n=200 , \\pi = 0.01)\\)\nDus \\(E(\\underline{k}) = n*\\pi = 200*0.01 =2\\) en \\(var(\\underline{k}) = n*\\pi*(1-\\pi) = 200*0.01*0.99 = 1.98\\)\nOmdat n groot is en \\(\\pi\\) zeer klein mag de binomiale verdeling benaderd wordeen door een Poissonverdeling met \\(\\mu\\) = 2.\n\\(\\underline{k} \\sim Poisson(\\mu = 2)\\)\n\ndpois(8,2)\n\n[1] 0.0008592716\n\n\nDeze kans is veel kleiner dan \\(\\alpha\\), dus \\(H_0\\) verwerpen, dus de bewering van de fabrikant klopt niet.\n\nqpois(0.99, 2)\n\n[1] 6\n\ndpois(7, 2)\n\n[1] 0.003437087\n\ndpois(6, 2)\n\n[1] 0.0120298\n\n\nKritieke gebied: \\(Z = \\{7,8,9,...\\}\\) want \\(P(k \\ge 7) \\lt 0.01\\) terwijl \\(P(k \\ge 6) \\gt 0.01\\)"
  },
  {
    "objectID": "z-toets.html#sec-ztoets-functie",
    "href": "z-toets.html#sec-ztoets-functie",
    "title": "5  Z-Toets",
    "section": "5.1 Functie",
    "text": "5.1 Functie\nEen zelf gebouwde functie.\n\nztest = function(x,mu,popvar){\n  one.tail.p <- NULL\n  z.score <- round((mean(x) - mu)/(popvar/sqrt(length(x))),3)\n  one.tail.p <- round(pnorm(abs(z.score),lower.tail = FALSE),3)\n  cat(\" z =\",z.score,\"\\n\", \n      \"1-zijdige waarschijnlijkheid =\", one.tail.p,\"\\n\", \n      \"2-zijdige waarschijnlijkheid =\", 2*one.tail.p )\n}"
  },
  {
    "objectID": "t-toets.html#sec-ttoets-1",
    "href": "t-toets.html#sec-ttoets-1",
    "title": "6  t-toets",
    "section": "6.1 t-toets voor 1 steekproef",
    "text": "6.1 t-toets voor 1 steekproef\n\nVoorbeeld 6.1 Een bedrijf stelt dat gemiddeld hoogstens 200 vervuilingseenheden (VE’s) per dag geloosd worden. De resultaten van een controle op 10 willekeurige dagen zijn: 190, 250, 320, 410, 310, 280, 230, 370, 350, 290. Toets of het bedrijf gelijk heeft met \\(\\alpha = 0.01\\).\n(Bron: boek Buijs, hfst. 9, voorbeeld 11)\nDe hypothesen worden als volgt geformuleerd:\n\n\\(H_0: \\mu \\le 200\\)\n\\(H_1: \\mu \\gt 200\\) (Dus een rechts eenzijdige toetsing)\n\nToetsingsgrootheid \\(\\bar{x}\\) : het steekproefgemiddelde\n\\(\\bar{x} \\sim t\\)\n\nve <- c(190, 250, 320, 410, 310, 280, 230, 370, 350, 290)\nt.test(x = ve, mu = 200, alternative = c(\"greater\"), conf.level = 0.99)\n\n\n    One Sample t-test\n\ndata:  ve\nt = 4.7434, df = 9, p-value = 0.0005269\nalternative hypothesis: true mean is greater than 200\n99 percent confidence interval:\n 240.5189      Inf\nsample estimates:\nmean of x \n      300 \n\n\nDe berekende t-waarde 4.74 heeft een p-waarde van 0.0005. Deze is kleiner dan \\(\\alpha\\) dus \\(H_0\\) wordt verworpen, het bedrijf heeft geen gelijk.\n\n\nVoorbeeld 6.2 Een vulmachine vult flessen met 500 ml vruchtensap. Het vulvolume volgt een normale verdelingt. Om te onderzoeken of de machine de flessen met een te laag volume afvult, wordt een steekproef van 20 flessen onderzocht. De waarnemingen staan in het bestand bottles.csv.\n(Bron: boek “using R for Statistics”, Sarah Stowell, chapter 10)\n\nbottles <- read.csv(file = \"data/bottles.csv\", header = TRUE)\nmean(bottles$Volume)\n\n[1] 491.5705\n\n\nHet gevonden gemiddelde is inderdaad minder dan 500. Dit kan toeval zijn. Toets daarom met een t-test of het gemiddelde significant minder dan 500 is en \\(\\alpha = 0.01\\).\n\n\\(H_0 : \\mu = 500\\)\n\\(H_1 : \\mu \\lt 500\\) (Dit is dus een links eenzijdige toetsing)\n\n\nt.test(x = bottles$Volume, mu = 500, alternative = \"less\", conf.level = 0.99)\n\n\n    One Sample t-test\n\ndata:  bottles$Volume\nt = -1.5205, df = 19, p-value = 0.07243\nalternative hypothesis: true mean is less than 500\n99 percent confidence interval:\n     -Inf 505.6495\nsample estimates:\nmean of x \n 491.5705 \n\n\nVoor het eenzijdige betrouwbaarheidsinterval geldt dat het gemiddelde volume minder is dan 505.65.\nDe p-waarde is groter dan het significantieniveau van 0.01, de nulhypothese kan niet verworpen worden. Er is dus geen bewijs dat het gemiddelde vulvolume minder dan 500 ml is."
  },
  {
    "objectID": "t-toets.html#sec-ttoets-2-onafhankelijk",
    "href": "t-toets.html#sec-ttoets-2-onafhankelijk",
    "title": "6  t-toets",
    "section": "6.2 t-toets voor twee onafhankelijke steekproeven",
    "text": "6.2 t-toets voor twee onafhankelijke steekproeven\nDit is de meest gebruikte t-toets. Hierbij worden de gemiddelden van twee willekeurige steekproeven met elkaar vergeleken. Naast onafhankelijkheid wordt aangenomen dat beide steekproeven uit normale verdelingen zijn gehaald waarvan de populatiegemiddelden en varianties onbekend zijn.\nEen typisch voorbeeld is bijvoorbeeld de concentratie van een medicijn in het bloed van twee verschillende groepen. En je zou graag willen weten of het waarschijnlijk is dat deze twee groepen verschillen met betrekking tot deze variabele.\n\n\\(H_0 : \\mu_1 = \\mu_2\\) - De populatiegemiddelden zijn gelijk.\n\\(H_1 : \\mu_1 \\ne \\mu_2\\) - De populatiegemiddelden zijn niet gelijk (tweezijdige toetsing)\n\nDe formele toetsing van de nulhypothese doet de volgende aannames:\n\n\\(H_0\\) is waar.\nDe onderzochte groepen zijn onafhankelijk (hebben geen overlap).\nDe gegevens zijn normaal verdeeld.\nDe varianties van de twee steekproeven zijn gelijk.\n\nAlle bovenstaande aannames moeten kloppen, of redelijk dicht in de buurt komen om de test een nauwkeurig resultaat te geven.\n\nAanname 1 is natuurlijk belangrijk, maar zit ingebakken in de toetsingsprocedure.\nAanname 2 is vanuit het oogpunt van de statistische praktijk fundamenteel.\nAanname 3. is erg belangrijk, maar het is relatief eenvoudig te controleren.\nWannneer aanname 4 niet klopt zijn er andere tests en oplossingen voor deze situaties, zoals een Welch’s t-toets (Satterthwaite ).\n\n\n\n\n\n\n\nOpmerking\n\n\n\nWanneer de gegevens niet normaal verdeeld zijn of er zijn serieuze uitschieters, dan is een Mann-Whitney U test het beste alternatief.\n\n\n\nVoorbeeld 6.3 Om te onderzoeken of vrouwen van 40 jaar gemiddeld zwaarder zijn dan vrouwen van 30 jaar wordt uit beide groepen een aselecte steekproef genomen van 20 personen. getoetst wordt met \\(\\alpha = 0.05\\).\n(Inspiratiebron: https://nl.wikipedia.org/wiki/T-toets)\nIn dit voorbeeld worden de data gesimuleerd.\n\n# simulatie data\nset.seed(234)\nv30 <- round(rnorm(n=20, mean=69, sd= 16.0), 0) # groep vrouwen 30 jaar\nv40 <- round(rnorm(n=20, mean=73, sd= 14.6), 0) # groep vrouwen 40 jaar\nmean(v30); mean(v40)\n\n[1] 67.7\n\n\n[1] 71.45\n\n\nNu de t-toets\n\nt.test(x=v30, y=v40)\n\n\n    Welch Two Sample t-test\n\ndata:  v30 and v40\nt = -0.74441, df = 33.52, p-value = 0.4618\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -13.992892   6.492892\nsample estimates:\nmean of x mean of y \n    67.70     71.45 \n\n\n\\(p\\) is groter dan \\(\\alpha\\), de nulhypothese wordt niet verworpen. Weliswaar waren de vrouwen van 40 in de steekproef gemiddeld 3.75 kg zwaarder dan de vrouwen van 30, maar dit verschil is niet significant gezien de spreiding binnen de groepen.\n\n\n6.2.1 Stapeling\nBij een t.test voor twee steekproeven kunnen de gegevens zowel in gestapelde als ongestapelde vorm aanwezig zijn. De gegevens zijn in gestapelde vorm wanneer er een variabele is voor de waarden en een andere variabele voor de categorieën. De gegevens zijn in ongestapelde vorm wanneer de waarden voor elke elke steekproef in een afzonderlijke variabele zitten, de vorm van een kruistabel. Zie het voorbeeld in de volgende afbeelding.\n\n\n\nFiguur: gestapelde en ongestapelde gegevens\n\n\ngestapelde vorm\nt.test(waarde~groep, dataset)\nHierbij is waarde de variabelenaam voor de waarden en groep de variabelenaam voor de namen van de groepen.\nWanneer de variabele voor de groepen meer dan twee niveaus bevat moet aangegeven worden welke twee groepen met elkaar vergeleken moeten worden, bijvoorbeeld: t.test(waarde~groep, dataset, groep %in% c(\"groep1\", \"groep2\"))\nongestapelde vorm\nt.test(dataset$groep1, dataset$groep2)\nStandaard gaat R er van uit dat de varianties voor de twee steekproeven verschillend zijn. Is de veronderstelling dat deze varianties wel gelijk zijn, dan kan dat aangegeven worden met het argument var.equal=TRUE. Er wordt dan een variantieschatting van de samengevoegde gegevens gemaakt. Of de varianties wel/niet gelijk zijn kan weer getoetst worden met de F-toets.\nOok kan bij de t-test voor twee onafhankelijke steekproeven een eenzijdige toetsing via het alternative argument worden gespecificeerd. Bij alternative = \"greater\" is de alternatieve hypothese dat het gemiddelde voor de eerste groep groter is dan het gemiddelde voor de tweede groep. Analoog voor de waarde “less”. Bij het gebruik van gestapelde gegevens moet je via de functie levels eerst bepalen welke de eerste en welke de tweede groep is.\n\nVoorbeeld 6.4 De dataset iris welke standaard in R be zit, bevat voor elk van de soorten setosa, versicolor en virginica steeds 50 waarnemingen in centimeters van de variabelen Sepal.Length, Sepal.Width, Petal.length en Petal.Width. (sepal = kelkblad, petal = bloemblad).\nVoer een t.test uit om te bepalen of er een significant verschil is in de gemiddelde Sepal.Width voor de soorten versicolor en virginica. Ga er hierbij vanuit dat Sepal.Width normaal verdeeld is en dat de variantie voor de twee groepen gelijk is.\n(Bron: boek “using R for Statistics”, Sarah Stowell, chapter 10)\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nEr zijn 150 records, 50 voor elke soort. De gegevens zijn in gestapelde vorm. De groep versicolor komt voor groep virginica.\nToetsingsgrootheid : \\(v\\) = gemiddelde Sepal.Width versicolor - gemiddelde Sepal.Width virginica\n\\(H_0 : v = 0\\)\n\\(H_1 : v \\neq 0\\):\nDe t-toets:\n\nt.test(Sepal.Width~Species, iris, Species %in% c(\"versicolor\", \"virginica\"), var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  Sepal.Width by Species\nt = -3.2058, df = 98, p-value = 0.001819\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.33028246 -0.07771754\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   2.770                    2.974 \n\n\nHet 95% betrouwbaarheidsinterval voor het verschil loopt van -0.330 tot -0.078 wat inhoudt dat het gemiddelde van Sepal.Width voor versicolor tussen de 0.078 en 0.330 centimeter minder is dan voor virinica. De p-waarde van 0.001819 is kleiner dan \\(\\alpha\\) = 0.05. Dus \\(H_0\\) wordt afgewezen, dus het gemiddelde Sepal.Width is voor de soorten versicolor en virginica niet gelijk."
  },
  {
    "objectID": "t-toets.html#sec-ttoets-2-gepaard",
    "href": "t-toets.html#sec-ttoets-2-gepaard",
    "title": "6  t-toets",
    "section": "6.3 t-toets voor twee gepaarde steekproeven",
    "text": "6.3 t-toets voor twee gepaarde steekproeven\nEen gepaarde t.test kan uitgevoerd worden via het argument paired = TRUE. De gegevens moeten hetzelfde aantal waarnemingen voor elke groep hebben, zodat er een 1-op-1 relatie tussen de waarnemingen in elke groep is. Voor de rest is de werkwijze gelijk aan de t-toets voor twee onafhankelijke steekproeven.\n\nVoorbeeld 6.5 Het bestand brains.csv bevat het hersenvolume van tien eeneiige tweelingen in cm3, zowel van van de eerstgeborene (Twin1) als van de laatst geborene (Twin2).\n(Bron: boek “using R for Statistics”, Sarah Stowell, chapter 10)\n\nbrains <- read.csv(file = \"data/brains.csv\", header = TRUE)\nknitr::kable(brains)\n\n\n\n\nPair\nTwin1\nTwin2\n\n\n\n\n1\n1005\n963\n\n\n2\n1035\n1027\n\n\n3\n1281\n1272\n\n\n4\n1051\n1079\n\n\n5\n1034\n1070\n\n\n6\n1079\n1173\n\n\n7\n1104\n1067\n\n\n8\n1439\n1347\n\n\n9\n1029\n1100\n\n\n10\n1160\n1204\n\n\n\n\n\nToets met een t-toets of er een relatie is tussen het hersenvolume en geboortevolgorde. Ga er vanuit dat het hersenvolume normaal verdeeld is. De gegevens zijn vanzelfsprekend gepaard omdat Twin1 van een geboorte correspondeert met Twin2 van dezelfde geboorte. Een gepaarde t-toets is dus geschikt. Omdat verschillen in elke richting interessant zijn wordt een tweezijdige toets gebruikt.\nToetsingsgrootheid : v = \\(\\mu_{Twin1} - \\mu_{Twin2}\\)\n\\(H_0 : v = 0\\)\n\\(H_1 : v \\neq 0\\):\n\nt.test(brains$Twin1, brains$Twin2, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  brains$Twin1 and brains$Twin2\nt = -0.47424, df = 9, p-value = 0.6466\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -49.04566  32.04566\nsample estimates:\nmean difference \n           -8.5 \n\n\nHet gemiddelde verschil in hersenvolume is -8.5, wat inhoudt dat het hersenvolume van de eerstgeborene gemiddeld 8.5 cm3 minder is dan van de laatstgeborene. Het 95% betrouwbaarheidsinterval loopt van -49 to 32 cm3. De waarde van -8.5 ligt hierin.\nDe p-waarde van 0.6466 is groter dan 5%, dus de nulhypothese kan niet verworpen worden, er is dus geen bewijs dat het hersenvolume gerelateerd is aan de volgorde van geboorte.\n\n\nVoorbeeld 6.6 Is een afslankproduct wel effectief zoals de fabrikant beweert? Om dat na te gaan worden 25 proefpersonen gevolgd. Elk worden ze gewogen voor ze aan de kuur beginnen en erna.\n(Inspiratiebron: https://nl.wikipedia.org/wiki/T-toets#Definitie_bij_gepaarde_steekproeven)\n\n# Simulatie data\naantal = 25\nset.seed(2345)\nx <- round(rnorm(n = aantal, mean = 99.5, sd = 26.2), 0)\ny <- round(rnorm(n = aantal, mean = 92.2, sd = 20.1), 0)\n\ndf <- data.frame(persoon = seq(1:aantal), \n                 begin = round(rnorm(n = aantal, mean = 99.5, sd = 26.2), 0), \n                 eind = round(rnorm(n = aantal, mean = 92.2, sd = 20.1), 0))\n\nt.test(df$begin, df$eind, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  df$begin and df$eind\nt = 0.9381, df = 24, p-value = 0.3575\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -7.680468 20.480468\nsample estimates:\nmean difference \n            6.4 \n\n\nDe p-waarde van 0.3575 is groter dan 5%, dus de nulhypothese kan niet verworpen worden, er is dus geen bewijs dat het afslankproduct effectief is."
  },
  {
    "objectID": "f-toets.html#sec-ftoets-toetsing",
    "href": "f-toets.html#sec-ftoets-toetsing",
    "title": "7  F-Toets",
    "section": "7.1 Toetsing",
    "text": "7.1 Toetsing\nNet als bij de t-test kunnen de gegevens in gestapelde en ongestapelde vorm zijn.\ngestapelde vorm: var.test(waarde ~ groep, dataset), met waarde de variabelenaam voor de waarden en groep de variabelenaam voor de groepen.\nWanneer de variabele voor de groepen meer dan twee niveaus bevat moet aangegeven worden welke twee groepen met elkaar vergeleken moeten worden, bijvoorbeeld: var.test(waarde ~ groep, dataset, groep %in% c(\"groep1\", \"groep2\"))\nongestapelde vorm: var.test(dataset$groep1, dataset$groep2)\nOptionele argumenten:\n\nratio = 1, de nulhypothese van de verhouding van de varianties van de populaties, defaultwaarde 1\nalternative = c(\"two.sided\", \"less\", \"greater\") , specificeert de alternatieve hypothese, defaultwaarde \"two.sided\"\nconf.level = 0.95, specificeert het betrouwbaarheidsinterval, defaultwaarde 0.95"
  },
  {
    "objectID": "f-toets.html#sec-ftoets-vb",
    "href": "f-toets.html#sec-ftoets-vb",
    "title": "7  F-Toets",
    "section": "7.2 Voorbeelden",
    "text": "7.2 Voorbeelden\n\nVoorbeeld 7.2 De dataset iris welke standaard in R be zit, bevat voor elk van de soorten setosa, versicolor en virginica steeds 50 waarnemingen in centimeters van de variabelen Sepal.Length, Sepal.Width, Petal.length en Petal.Width. (sepal = kelkblad, petal = bloemblad). Om een t-test uit te voeren voor het toetsen van gelijke gemiddeldes van de variabele Sepal.Width voor de soorten versicolor en virginica.\n(Bron: boek “using R for Statistics”, Sarah Stowell, chapter 10)\nToetsingsgrootheid : \\(F\\)\n\\(H_0 : F = 1\\), de varianties van de populaties zijn gelijk\n\\(H_1: F \\neq 1\\), de varianties van de populaties zijn verschillend\nDe F-toets:\n\nvar.test(Sepal.Width~Species, iris, Species %in% c(\"versicolor\", \"virginica\"))\n\n\n    F test to compare two variances\n\ndata:  Sepal.Width by Species\nF = 0.94678, num df = 49, denom df = 49, p-value = 0.849\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5372773 1.6684117\nsample estimates:\nratio of variances \n         0.9467839 \n\n\n\n\nVoorbeeld 7.3 Twee steekproeven\n(Bron: Two sample Student’s t-test #1)\nToetsingsgrootheid : F\n\\(H_0 : F = 1\\), de varianties van de populaties zijn gelijk\n\\(H_1: F \\neq 1\\), de varianties van de populaties zijn verschillend\n\nA <- c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179)\nB <- c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180)\nvar.test(A, B)\n\n\n    F test to compare two variances\n\ndata:  A and B\nF = 2.1028, num df = 9, denom df = 9, p-value = 0.2834\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5223017 8.4657950\nsample estimates:\nratio of variances \n          2.102784 \n\n\nDe p-waarde is groter dan 0.05 dus \\(H_0\\) niet verwerpen, de varianties kunnen gelijk zijn."
  },
  {
    "objectID": "chikwadraat.html#sec-chi-rsyntax",
    "href": "chikwadraat.html#sec-chi-rsyntax",
    "title": "8  Chi-Kwadraat toets",
    "section": "8.1 R Syntax",
    "text": "8.1 R Syntax\nDe syntax van de chisq.test() functie is:\nchisq.test(x, y = NULL, correct = TRUE, p = rep(1/length(x), length(x)), rescale.p = FALSE, simulate.p.value = FALSE, B = 2000)\nWelke soort toets uitgevoerd wordt hangt van van de soort gegevens. Wanneer x een numerieke vector is of een 1-dimensionale tabel met numerieke waarden, dan wordt een aanpassingstoets uitgevoerd, waarbij de waarden van x opgevat worden als de waargenomen frequenties. Wanneer x een 2-dimensionale tabel, array of matrix is dan wordt dat gezien als een tabel van frequenties en wordt een test voor onafhankelijkheid uitgevoerd.\nEen waarde voor y kan meestal genegeerd worden.\ncorrect = TRUE gebruiken wanneer een continuiteitscorrectie moet worden toegepast. Geef deze de waarde FALSE wanneer het niet wenselijk is.\nVoor de aanpassingstoets maak p gelijk aan aan de onder de \\(H_0\\) hypothese veronderstelde kansen voor elke categorie in vector x. De som hiervan moet exact gelijk zijn aan 1. Voor de onafhankelijkheidstoets is het argument p irrelevant omdat de verwachte frequenties berekend worden."
  },
  {
    "objectID": "chikwadraat.html#sec-chi-aanpassing",
    "href": "chikwadraat.html#sec-chi-aanpassing",
    "title": "8  Chi-Kwadraat toets",
    "section": "8.2 Aanpassingstoets",
    "text": "8.2 Aanpassingstoets\n\nVoorbeeld 8.1 Rozen\nBij het kruisen van bepaalde soorten rode en witte rozen verkrijg je rode, witte en roze rozen. Volgens de theorie moet je deze in een verhouding krijgen van rood : wit : roze = 3:2:2. In een steekproef van gekruiste rozen zitten 35 rode, 31 witte en 14 roze rozen. Test met een chikwadraattoets (\\(\\alpha = 5\\%\\)) of de theorie klopt. (Bron Klingenberg)\n\n\\(H_0\\): theorie klopt, verdeling rood:wit:roze = 3:2:2\n\\(H_1\\): theorie klopt niet\n\n\nchisq.test(c(35, 31, 14), p = c(3, 2, 2)/7)\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(35, 31, 14)\nX-squared = 6.3479, df = 2, p-value = 0.04184\n\n\nConclusie: De p-waarde van 0.04184 is kleiner dan \\(\\alpha\\), dus \\(H_0\\) afwijzen, er is voldoende bewijs dat de veronderstelde theoretische verhouding waarschijnlijk niet klopt.\n\n\nVoorbeeld 8.2 Dobbelsteen\nIemand gooit 60 keer met een dobbelsteen en telt de ogenaantallen. Bij een zuivere dobbelsteen is de verwachting om elk van de ogenaantallen ongeveer 10 keer te gooien. Hij vindt als uitkomst voor de ogenaantallen 1 tot en met 6 resp. de waarden: 13, 9, 8, 11, 5, 14. Test met een chikwadraattoets (\\(\\alpha = 5\\%\\)) of de dobbelsteen zuiver is. Bron: (wikipedia)\n\n\\(H_0\\): dobbelsteen is zuiver, kans voor elk ogenaantal is 1/6\n\\(H_1\\): dobbelsteen is niet zuiver\n\n\nchisq.test(c(13, 9, 8, 11, 5, 14), p = rep(1/6, 6))\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(13, 9, 8, 11, 5, 14)\nX-squared = 5.6, df = 5, p-value = 0.3471\n\n\nConclusie: De p-waarde van 0.3471 is veel groter dan \\(\\alpha\\), dus \\(H_0\\) accepteren, er is geen reden om aan de zuiverheid van de dobbelsteen te twijfelen.\n\n\nVoorbeeld 8.3 Boekomslag\nBron: boek Buijs, voorbeeld 3, pag. 265-266\nEen boek is verkocht met 4 verschillende omslagen (A, B, C en D). Verondersteld wordt dat van alle 4 soorten boeken evenveel exemplaren verkocht worden, dus een gelijkmatige verdeling. Bij een experiment met 200 verkochte boeken zijn de volgende resultaten gevonden.\n\nomslag <- c(42, 68, 52, 38)\nas.table(omslag)\n\n A  B  C  D \n42 68 52 38 \n\n\nToets de veronderstelling met \\(\\alpha = 5\\%\\)\n\n\\(H_0\\): verkochte aantallen is voor elke omslag even groot\n\\(H_1\\): verkochte aantallen zijn per omslag verschillend\n\n\nchisq.test(omslag , p = rep(1/4, 4))\n\n\n    Chi-squared test for given probabilities\n\ndata:  omslag\nX-squared = 10.72, df = 3, p-value = 0.01334\n\n\nConclusie: De p-waarde van 0.01334 is kleiner dan \\(\\alpha\\), dus \\(H_0\\) afwijzen. De voorkeuren voor de omslagen zijn niet gelijk.\n\n\nVoorbeeld 8.4 Drukfouten\nBron: boek Buijs, voorbeeld 4, pag. 267-268\nIn onderstaande tabel staat het aantal drukfouten per pagina in een boek van 150 pagina’s.\n\n\n\nAantal fouten (k) per pagina\n0\n1\n2\n3\n4 of meer\n\n\n\n\nAantal pagina’s met k drukfouten\n60\n50\n25\n10\n5\n\n\n\nGa met een chikwadraattoets na of het aantal drukfouten per pagina Poisson verdeeld is met \\(\\mu = 1\\).\nDefinitie: \\(\\underline{k}\\) = aantal drukfouten per pagina.\n\n\\(H_0\\): \\(\\underline{k}\\) is Poisson verdeeld met \\(\\mu = 1\\)\n\\(H_1\\): \\(\\underline{k}\\) is NIET Poisson verdeeld met \\(\\mu = 1\\)\n\nEerst berekening van de kansen voor de verschillende waarden van k.\n\n# aantal fouten per pagina\nk <- 0:4\n# theoretische frequenties volgens Poisson verdeling\nprob <- dpois(k,1)\n# correctie voor \"4 fouten of meer\",nu ook som alle probs = 1\nprob[5] <- 1 - sum(prob[1:4])\nprob\n\n[1] 0.36787944 0.36787944 0.18393972 0.06131324 0.01898816\n\n\nNu kan de chikwadraattoets uitgevoerd worden.\n\nfouten <- c(60, 50, 25, 10, 5)\ntoets <- chisq.test(x = fouten, p = prob )\ntoets\n\n\n    Chi-squared test for given probabilities\n\ndata:  fouten\nX-squared = 2.8463, df = 4, p-value = 0.5839\n\ntoets$expected\n\n[1] 55.181916 55.181916 27.590958  9.196986  2.848224\n\n\nDe p-waarde is veel groter dan \\(\\alpha\\) dus \\(H_0\\) wordt niet verworpen, het aantal drukfouten per pagina kan Poisson verdeeld zijn.\n\nDe test geeft een waarschuwing “Chi-squared approximation may be incorrect” omdat er één of meerdere theoretische frequenties erg klein zijn. Een vuistregel is dat er geen theoretische frequenties kleiner dan 5 moeten zijn. Is dat wel het geval dan kun je eventueel klassen samenvoegen.\nDe laatste twee klassen worden nu samengevoegd waarna de chikwadraattoets opnieuw wordt uitgevoerd.\n\n\n# aantal fouten per pagina\nk2 <- 0:3\n# theoretische frequenties volgens Poisson verdeling\nprob2 <- dpois(k2,1)\n# correctie voor \"3 fouten of meer\",nu ook som alle probs = 1\nprob2[4] <- 1 - sum(prob2[1:3])\nprob2\n\n[1] 0.3678794 0.3678794 0.1839397 0.0803014\n\nfouten2 <- c(60, 50, 25, 15)\ntoets2 <- chisq.test(x = fouten2, p = prob2 )\ntoets2\n\n\n    Chi-squared test for given probabilities\n\ndata:  fouten2\nX-squared = 1.8754, df = 3, p-value = 0.5987\n\ntoets2$expected\n\n[1] 55.18192 55.18192 27.59096 12.04521"
  },
  {
    "objectID": "chikwadraat.html#sec-chi-onafhankelijkheid",
    "href": "chikwadraat.html#sec-chi-onafhankelijkheid",
    "title": "8  Chi-Kwadraat toets",
    "section": "8.3 Onafhankelijkheidstoets",
    "text": "8.3 Onafhankelijkheidstoets\nDe chi-kwadraattoets voor onafhankelijkheid test of twee kwalitatieve variabelen onafhankelijk zijn, of er dus een relatie bestaat tussen twee categoriale variabelen.\n\n\\(H_0\\): de variabelen zijn onafhankelijk, er is geen relatie tussen de twee categoriale variabelen.\n\\(H_1\\): de variabelen zijn afhankelijk, er is een relatie tussen de twee categoriale variabelen.\n\nLET OP: Deze toets kan alleen gedaan worden wanneer de verwachte frequenties in alle groepen groter of gelijk aan 5 zijn.\n\nVoorbeeld 8.5 Haarkleur-Oogkleur relatie\nIn een steekproef van 65 studenten is de haarkleur (categorieën blond, bruin, donker) en oogkleur (categorieën licht, donker) vastgelegd. De onderstaande tabel vat de tellingen samen. (Bron Klingenberg)\n\nkleuren <- matrix(c(12, 2, 8, 25, 6, 12), ncol = 3)\ncolnames(kleuren) <- c(\"blond\", \"bruin\", \"zwart\")\nrownames(kleuren) <- c(\"licht\", \"donker\")\nkleuren\n\n       blond bruin zwart\nlicht     12     8     6\ndonker     2    25    12\n\n\nTest met een chikwadraattoets(\\(\\alpha = 5\\%\\)) of haarkleur en oogkleur met elkaar geassocieerd zijn.\n\n\\(H_0\\): haarkleur en oogkleur zijn onafhankelijk van elkaar\n\\(H_1\\): haarkleur en oogkleur zijn met elkaar verbonden\n\n\ntest <- chisq.test(kleuren)\ntest\n\n\n    Pearson's Chi-squared test\n\ndata:  kleuren\nX-squared = 15.938, df = 2, p-value = 0.000346\n\n\nJe kunt de verschillende waarden ook afzonderlijk opvragen:\n\ntest$method    # toetsingsmethode\n\n[1] \"Pearson's Chi-squared test\"\n\ntest$statistic # chikwadraat waarde\n\nX-squared \n 15.93795 \n\ntest$p.value   # p-waarde\n\n[1] 0.0003460333\n\ntest$parameter # aantal vrijheidsgraden\n\ndf \n 2 \n\ntest$observed  # waargenomen frequenties\n\n       blond bruin zwart\nlicht     12     8     6\ndonker     2    25    12\n\ntest$expected  # verwachte frequenties\n\n       blond bruin zwart\nlicht    5.6  13.2   7.2\ndonker   8.4  19.8  10.8\n\ntest$residuals # residuen, (observed - expected) / sqrt(expected).\n\n           blond     bruin      zwart\nlicht   2.704494 -1.431253 -0.4472136\ndonker -2.208210  1.168613  0.3651484\n\n\nConclusie: De p-waarde van 0.000346 is veel kleiner dan \\(\\alpha\\), dus \\(H_0\\) afwijzen, er is een significante relatie tussen haarkleur en oogkleur.\n\n\nVoorbeeld 8.6 Betaalgedrag en leeftijd\nBron: boek Buijs, voorbeeld 6, pag. 272-273\nEen bank onderzoekt van 100 verstrekte leningen hoe de aflossingen zijn verlopen. De bank wil onderzoeken of het betaalgedrag afhangt van de leeftijd van de leners.\n\nafbetaling <- rbind(c(24, 36), c(6, 34))\ndimnames(afbetaling) = list(Leeftijd = c(\"jonger dan 40\", \"40 of ouder\"), \n                            Betaalgedrag = c(\"Wanbetalers\", \"Correct\"))\nafbetaling\n\n               Betaalgedrag\nLeeftijd        Wanbetalers Correct\n  jonger dan 40          24      36\n  40 of ouder             6      34\n\n\nMet rij- en kolomsommen:\n\naddmargins(afbetaling)\n\n               Betaalgedrag\nLeeftijd        Wanbetalers Correct Sum\n  jonger dan 40          24      36  60\n  40 of ouder             6      34  40\n  Sum                    30      70 100\n\n\nEn weergegeven als fracties:\n\nprop.table(afbetaling)\n\n               Betaalgedrag\nLeeftijd        Wanbetalers Correct\n  jonger dan 40        0.24    0.36\n  40 of ouder          0.06    0.34\n\n\nHypothesen:\n\n\\(H_0\\): Er is onafhankelijkheid, betaalgedrag hangt niet af van leeftijd\n\\(H_1\\): Er is geen onafhankelijkheid, betaalgedrag hangt af van leeftijd\n\n\nchisq.test(afbetaling, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  afbetaling\nX-squared = 7.1429, df = 1, p-value = 0.007526\n\n\nDe berekende p-waarde is kleiner dan \\(\\alpha = 0.05\\) dus \\(H_0\\) wordt verworpen, het betaalgedrag hangt wel af van de leeftijd.\n\n\nVoorbeeld 8.7 Kiesgedrag Mannen-Vrouwen\nBron: boek Buijs, voorbeeld 7, pag. 274-275\nOnderzoek naar de voorkeur voor een politieke partij onder mannen en vrouwen, totaal 1000 personen.\n\npartijvoorkeur <- rbind(c(170, 230), c(210, 190), c(120, 80))\ndimnames(partijvoorkeur) = list(Partij = c(\"CDA\", \"PvdA\", \"VVD\"), Geslacht = c(\"man\",\"vrouw\"))\naddmargins(partijvoorkeur)\n\n      Geslacht\nPartij man vrouw  Sum\n  CDA  170   230  400\n  PvdA 210   190  400\n  VVD  120    80  200\n  Sum  500   500 1000\n\n\nDe tabel geeft een bepaald verschil te zien in de voorkeuren van mannen en vrouwen. Dat is nog beter te zien wanneer naar de fracties gekeken wordt:\n\nprop.table(partijvoorkeur)\n\n      Geslacht\nPartij  man vrouw\n  CDA  0.17  0.23\n  PvdA 0.21  0.19\n  VVD  0.12  0.08\n\n\nHypothesen:\n\n\\(H_0\\): Er is geen verschil in voorkeuren van man en vrouw\n\\(H_1\\): Er is wel verschil in voorkeuren van man en vrouw\n\n\nchisq.test(partijvoorkeur, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  partijvoorkeur\nX-squared = 18, df = 2, p-value = 0.0001234\n\n\nDe berekende p-waarde is kleiner dan \\(\\alpha = 0.05\\) dus \\(H_0\\) wordt verworpen, er is verschil in partijvoorkeur tussen mannen en vrouwen.\n\n\nVoorbeeld 8.8 Medicijntest\nOm de effectiviteit van een geneesmiddel te testen worden 105 patienten in twee groep verdeeld. Een groep van 50 patienten wordt met het medicijn behandeld en de resterende 55 patienten is een controlegroep. Na twee weken wordt de conditie van alle patienten onderzocht en vastgesteld of er al dan niet een verbetering is opgetreden. De resultaten zijn in de volgende tabel te zien.\n\ndf <- read.csv(\"data/medicijntest.csv\")\ntable(df$behandeling, df$verbetering)\n\n                \n                 niet-verbeterd verbeterd\n  behandeld                  15        35\n  niet-behandeld             29        26\n\n\nHypothesen:\n\n\\(H_0\\): Behandeling met het medicijn geeft geen verbetering\n\\(H_1\\): Behandeling met het medicijn geeft wel verbetering\n\nTest de hypothesen met een chikwadraattoets(\\(\\alpha = 5\\%\\)). De twee vectoren worden als input voor de functie gebruikt. Ook wordt het argument correct = FALSE opgenomenom de continuiteitscorrectie volgens Yates uit te schakelen.\n\nchisq.test(df$behandeling, df$verbetering, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  df$behandeling and df$verbetering\nX-squared = 5.5569, df = 1, p-value = 0.01841\n\n\nConclusie: De p-waarde van 0,01841 is kleiner dan \\(\\alpha\\), dus \\(H_0\\) afwijzen, er is dus voldoende bewijs om te veronderstellen dat behandeling met het medicijn een verbetering geeft."
  },
  {
    "objectID": "chikwadraat.html#sec-chi-homogeniteit",
    "href": "chikwadraat.html#sec-chi-homogeniteit",
    "title": "8  Chi-Kwadraat toets",
    "section": "8.4 Homogeniteitstoets",
    "text": "8.4 Homogeniteitstoets\nVergelijk proporties over twee groepen\n\nVoorbeeld 8.9 Voorkeur Ontbijtei\nAan een groep van 25 vrouwen en een groep van 17 mannen is gevraagd hoe ze het liefst hun ei op zondagmorgen willen hebben: Gebakken, Gekookt of Roerei. De gegevens zijn samengevat in onderstaande tabel.\n\neitje <- matrix(c(5, 9, 12, 3, 7, 5), ncol = 3)\ncolnames(eitje) <- c(\"Gebakken\", \"Gekookt\", \"Roerei\")\nrownames(eitje) <- c(\"Vrouwen\", \"Mannen\")\neitje\n\n        Gebakken Gekookt Roerei\nVrouwen        5      12      7\nMannen         9       3      5\n\n\nTest met een chikwadraattoets(\\(\\alpha = 5\\%\\)) of de voorkeuren gelijk verdeeld zijn voor mannen en vrouwen, dus of de verhoudingen homogeen zijn over beide groepen?\n\n\\(H_0\\): de verdelingen zijn voor mannen en vrouwen hetzelfde\n\\(H_1\\): de verdelingen zijn voor mannen en vrouwen verschillend\n\n\ntest <- chisq.test(eitje)\ntest\n\n\n    Pearson's Chi-squared test\n\ndata:  eitje\nX-squared = 5.8516, df = 2, p-value = 0.05362\n\n\nOmdat de aantallen klein zijn verschijnt er een waarschuwing dat de berekende waarden niet juist kunnen zijn. Een van de verwachte waarden is kleiner dan 5.\n\ntest$expected\n\n        Gebakken  Gekookt  Roerei\nVrouwen 8.195122 8.780488 7.02439\nMannen  5.804878 6.219512 4.97561\n\n\nJe kunt in deze test de p-waarden simuleren waardoor het resultaat iets betrouwbaarder wordt.\n\nchisq.test(eitje, simulate.p.value = TRUE, B = 10000)\n\n\n    Pearson's Chi-squared test with simulated p-value (based on 10000\n    replicates)\n\ndata:  eitje\nX-squared = 5.8516, df = NA, p-value = 0.05769\n\n\nConclusie: De p-waarde is iets groter dan \\(\\alpa\\), dus \\(H_0\\) accepteren, er is niet voldoende bewijs om te concluderen dat de verdelingen bij mannen en vrouwen verschillend is.\nTip: Een andere mogelijkheid is om fisher.test() te gebruiken."
  },
  {
    "objectID": "driehoekstest.html",
    "href": "driehoekstest.html",
    "title": "9  Driehoekstest",
    "section": "",
    "text": "Bij het uitvoeren van brouwexperimenten varieer je één component (ingrediënt of werkwijze) en hou je alle andere componenten constant. Je maakt dan twee brouwsels (bieren) waarbij dan alleen die ene component verschilt. Daarna ga je met je zintuigen (proeven, ruiken, zien) onderzoeken of je dit verschil ook kunt waarnemen. Dit type van onderzoek wordt ook wel sensorisch onderzoek genoemd.\nEen manier om statistisch te toetsen of de verschillen significant zijn is door het uitvoeren van een zogenaamde driehoekstest. Een aantal personen, hier verder panelleden genoemd, krijgen in willekeurige volgorde drie producten voorgelegd, waarvan er twee gelijk zijn en de derde dus afwijkt. Elk panellid moet het afwijkende product aanwijzen. Als het panellid het verschil niet met zijn zintuigen kan vaststellen, moet deze dus gokken. De gokkans is dus 1/3.\nVoor het brouwexperiment kun je de volgende hypotheses formuleren:\n\n\\(H_0\\): Er is geen verschil tussen de twee bieren. Dan is \\(p = \\frac{1}{3}\\) voor en goed antwoord en \\(p = \\frac{2}{3}\\) voor een fout antwoord.\n\\(H_1\\): Er is een daadwerkelijk verschil tussen de twee bieren.\n\nEen geschikte toetsingsgrootheid is \\(\\chi^2\\) (Chi-kwadraat).\n\nVoorbeeld 9.1 60 proefpersonen krijgen elk drie bekers met bier voorgezet. Twee bieren zijn hetzelfde (bier A) en één bier verschilt (bier B). In twee bekers zit dus A en in een beker zit B. De vraag is welk bier afwijkend is van de andere twee. Er worden 24 goede antwoorden en 36 foute antwoorden waargenomen.\nVoor de analyse wordt een chi-kwadraattoets uitgevoerd met \\(\\alpha = 0,05\\).\n\n\n\n\n\n\n\n\n\n\nAntwoord\nWaargenomen (\\(O_i\\))\nVerwacht (\\(E_i\\))\n\\((O_i - E_i)^2\\)\n\\(\\frac{(O_i - E_i)^2}{E_i}\\)\n\n\n\n\ngoed\n\\(24\\)\n\\(60*\\frac{1}{3}=20\\)\n\\(16\\)\n\\(\\frac{16}{20} = 0,80\\)\n\n\nfout\n\\(36\\)\n\\(60*\\frac{2}{3}=40\\)\n\\(16\\)\n\\(\\frac{16}{40} = 0,40\\)\n\n\nsom\n\\(60\\)\n\\(60\\)\n\n\\(1,20\\)\n\n\n\nDus \\(\\chi^2=1,20\\) en het aantal vrijheidsgraden is \\(n-1 = 2-1 = 1\\).\nDe grens voor het 95% gebied van een \\(\\chi^2[1]\\) verdeling is 3.8414588.\nDe berekende waarde van 1,20 ligt in het 95% gebied, dus de nulhypothese wordt niet verworpen, er is dus geen significant verschil tussen de bieren vastgesteld.\nDe driehoekstest kan ook in R uitgevoerd worden met de functie SensoMineR::triangle.pair.test()\n\nSensoMineR::triangle.pair.test(nb.good = 24, nb.answer = 60)\n\n[1] \"P-value of the Triangle test: 0.16854\"\n[1] \"At the 95% level, one can say that the panelists do not make the difference between the two products\"\n[1] \"The estimation (by  Maximum Likelihood) of panelist which really perceived the difference between the two products is: 6\"\n[1] \"The  Maximum Likelihood is:  0.11454\"\n[1] \"The minimum of panelists who should detect the odd product to can say that panelists perceive the difference between the products is: 27\"\n\n\n$p.value\n[1] 0.1685385\n\n$Estimation\n[1] 6\n\n$ML\n[1] 0.11454\n\n$minimum\n[1] 27"
  },
  {
    "objectID": "likelihood.html#sec-likelihood-bernoulli",
    "href": "likelihood.html#sec-likelihood-bernoulli",
    "title": "10  Maximum Likelihood",
    "section": "10.1 Bernoulli verdeling",
    "text": "10.1 Bernoulli verdeling\n30 waarnemingen met uitkomst 1 (=succes) of 0 (= geen succes)\n\n1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1\n\nDe succeskans van deze 30 waarnemingen = 22/30 = 0,7333. Wat is de MLE van de succeskans?\nVeronderstel dat we uitgaan dat van een succeskans 0,7. Dan is de kans op waarneming 1 gelijk aan 0,7 en de kans op waarneming 0 gelijk aan 0,3. De totale kans op deze 30 waarnemingen (de Likelihood) is dan het product van deze 30 afzonderlijke kansen. En omdat het product van kansen zorgt voor extreem kleine getallen, wordt meestal overgestapt op de natuurlijke logaritme van de kansen. Dan kun je i.p.v. het product de som nemen. De logaritme is een monotoon stijgende functie en de logaritme van een functie bereikt de maximum waarde op hetzelfde punt als de functie zelf.\n\nLikelihood: \\(P(x_1) * P(x_2) * P(x_3) ... * P(x_{30})\\)\nLog-Likelihood: \\(LN(P(x_1)) + LN(P(x_2)) + LN(P(x_3)) ... + LN(P(x_{30}))\\)\n\nIn dit voorbeeld is bij een succeskans van 0,7 de Likelihood = \\(0,7^{22}\\times 0,3^{8} = 2,565*10^{-8}\\). Zo kun je ook voor andere succeskansen steeds de Likelihood (totale kans) uitrekenen. De MLE is dan die kans waarvoor de Likelihood maximaal is. Dit is een iteratief proces.\nIn Excel kun je deze MLE met de Oplosser bepalen. Vanwege de zeer kleine waarden voor de Likelihood kan de Oplosser geen goed antwoord vinden. Bij de Log-Likelihood geeft de Oplosser als beste kans 0,7333. Dit is ook de theoretische waarde.\nIn R kun je een Likelihood functie definieren voor dit experiment en dan met functie optimize het maximum vinden.\n\n# bereken dichtheid 22 keer succes bij 30 pogingen en kans op succe p.\nlikelihood <- function(p) {\n  dbinom(22, 30, p)\n}\n\noptimize(f = likelihood, interval = c(0,1), maximum = TRUE)\n\n$maximum\n[1] 0.7333324\n\n$objective\n[1] 0.1628374"
  },
  {
    "objectID": "likelihood.html#sec-likelihood-normaal",
    "href": "likelihood.html#sec-likelihood-normaal",
    "title": "10  Maximum Likelihood",
    "section": "10.2 Normale verdeling",
    "text": "10.2 Normale verdeling\nInspiratiebron: https://medium.com/@lorenzojcducv/maximum-likelihood-for-the-normal-distribution-966df16fd031\nKans: \\(P(x|\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x - \\mu}{\\sigma})^2}\\)\nVoor het vinden van de optimale parameters voor het gemiddelde \\(\\mu\\) en de standaarddeviatie \\(sigma\\) gebruik je de Likelihood functie\nLikelihood: \\(L(\\mu,\\sigma |x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x - \\mu}{\\sigma})^2}\\)\n\nVoorbeeld 10.1 1 waarneming\nMeting gewicht (gram) van 1 gloeilamp: 32\nWat is de Likelihood voor een normale verdeling met \\(\\mu=28\\) en \\(\\sigma =2\\)?\n\\(L(\\mu=28,\\sigma=2 |x=32) = \\frac{1}{2\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{32 - 28}{2})^2}\\) = 0.0269955\nZie de volgende tabel voor een aantal andere waarden van \\(\\mu\\).\n\n\n\n\\(\\mu\\)\n\\(\\sigma\\)\nL\n\n\n\n\n28\n2\n0.0269955\n\n\n29\n2\n0.0647588\n\n\n30\n2\n0.1209854\n\n\n31\n2\n0.1760327\n\n\n32\n2\n0.1994711\n\n\n33\n2\n0.1760327\n\n\n34\n2\n0.1209854\n\n\n\nDe MLE voor \\(\\mu\\) wordt 32. Dit is een logische waarde, immers de uitkomst van de ene meting.\n\n\nVoorbeeld 10.2 2 waarnemingen\nMeting gewicht (gram) van 2 gloeilampen: 32 en 34\nWat is de Likelihood voor een normale verdeling met \\(\\mu=30\\) en \\(\\sigma =2\\)?\nDe metingen zijn onafhankelijk van elkaar zodat het product van de afzonderlijke kansen kunt gebruiken.\n\n\n\n\\(L(\\mu=30,\\sigma=2 |x=\\{32, 34\\}) = L(\\mu=30,\\sigma=2 |x=32) \\times L(\\mu=30,\\sigma=2 |x=34)\\) = 0.0032661\nZie de volgende tabel voor een aantal andere waarden van \\(\\mu\\).\n\n\n\n\\(\\mu\\)\n\\(\\sigma\\)\nL\n\n\n\n\n30\n2\n0.0032661\n\n\n31\n2\n0.0113997\n\n\n32\n2\n0.0241331\n\n\n33\n2\n0.0309875\n\n\n34\n2\n0.0241331\n\n\n35\n2\n0.0113997\n\n\n\nDe MLE voor \\(\\mu\\) wordt nu 33, een logische waarde omdat dit het gemiddelde van de twee waarnemingen is.\n\nn waarnemingen\nIn principe kun je de methode voor meerdere gegevenspunten uitbreiden. Je moet dan de afzonderlijke likelihood functies met elkaar vermenigvuldigen.\n\\(L(\\mu,\\sigma |x=\\{x_1, x_2, ..., x_n\\}) = L(\\mu,\\sigma |x_1) \\times L(\\mu,\\sigma |x_2) \\times ... \\times L(\\mu,\\sigma |x_n)\\)\n\\(= \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x_1 - \\mu}{\\sigma})^2} \\times ... \\times \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x_n - \\mu}{\\sigma})^2}\\)\nVoor het bepalen van de MLE moet je twee afgeleides bepalen en gelijk aan 0 stellen:\n\nAfgeleide naar \\(\\mu\\), waarbij \\(\\sigma\\) als een constante behandeld wordt.\nAfgeleide naar \\(\\sigma\\), waarbij \\(\\mu\\) als een constante behandeld wordt.\n\nHet bepalen van de afgeleides gaat gemakkelijker via de logaritmes. De Log Likelihood functie wordt \\(LL(\\mu,\\sigma|x) =ln(L(\\mu,\\sigma |x=\\{x_1, x_2, ..., x_n\\}))\\)\n\\(LL(\\mu,\\sigma|x) = ln(\\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x_1 - \\mu}{\\sigma})^2}) + ...+ ln(\\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x_n - \\mu}{\\sigma})^2})\\)\nBeschouw de eerste term.\n\\(ln(\\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}(\\frac{x_1 - \\mu}{\\sigma})^2}) = ln[(2\\pi \\sigma^2)^{-0.5}] -\\frac{(x_1 - \\mu)^2}{2\\sigma^2}\\)\n\\(= -0.5ln(2\\pi) - ln(\\sigma) - \\frac{(x_1 - \\mu)^2}{2\\sigma^2}\\)\nWanneer je dit ook voor alle andere termen doet dan kun je de Log Likelihood functie omzetten in\n\\(LL(\\mu,\\sigma|x) = -\\frac{n}{2}ln(2\\pi) - n ln(\\sigma) - \\sum_{i=1}^{n}\\frac{(x_i - \\mu)^2}{2 \\sigma^2}\\)\nAfgeleide naar \\(\\mu\\)\n\\(\\frac{\\partial}{\\partial \\mu} LL(\\mu,\\sigma|x) = \\sum_{i=1}^{n} \\frac{x_i - \\mu}{\\sigma^2} = \\frac{1}{\\sigma^2}(\\sum_{i=1}^{n}x_i -n\\mu)\\)\nGelijkstelling aan nul levert\n\\(\\mu = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\)\nDe MLE voor \\(\\mu\\) is dus het gemiddelde van de waarnemingen.\nAfgeleide naar \\(\\sigma\\)\n\\(\\frac{\\partial}{\\partial \\sigma} LL(\\mu,\\sigma|x) = -\\frac{n}{\\sigma} + \\sum_{i=1}^{n} \\frac{(x_i - \\mu)^2}{\\sigma^3}\\)\nGelijkstelling aan nul levert.\n\\(\\sum_{i=1}^{n} \\frac{(x_i - \\mu)^2}{\\sigma^3} = \\frac{n}{\\sigma}\\) ofwel\n\\(\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\mu)^2}{n}}\\)\nDe MLE voor \\(\\sigma\\) is dus de standaardafwijkingen van de waarnemingen.\nfunctie nlm\nDe R-functie nlm() minimaliseert willekeurige functies geschreven in R. Voor het maximaliseren van de likelihood moet je als input de negatieve waarde van de log-likelihood gebruiken, immers minimaliseren van \\(-f\\) komt overeen met het maximaliseren van \\(f\\)."
  },
  {
    "objectID": "eda.html#sec-eda-steam",
    "href": "eda.html#sec-eda-steam",
    "title": "11  Exploratieve Data Analyse (EDA)",
    "section": "11.1 STEAM project",
    "text": "11.1 STEAM project\nBron: STEAM project\n\n# Data\nurl <- \"https://raw.githubusercontent.com/lgellis/STEM/master/DATA-ART-1/Data/FinalData.csv\"\n# download.file(url, file.path(\"data\", \"FinalData.csv\"))\ndf <- read_csv(\"data/FinalData.csv\", col_names = TRUE)\n\nHEAD en TAIL\n\nhead(df)\n#> # A tibble: 6 × 17\n#>      ID Gender Grade Horoscope Subject IntExt     OptPest  Scree…¹ Sleep PhysA…²\n#>   <dbl> <chr>  <dbl> <chr>     <chr>   <chr>      <chr>      <dbl> <dbl>   <dbl>\n#> 1     1 male       4 Scorpio   Math    Extravert  Optimist       1     7      10\n#> 2     2 female     4 Capricorn Gym     Extravert  Optimist       1     8       5\n#> 3     3 male       4 Taurus    Math    Introvert  Optimist       4     9      22\n#> 4     4 male       4 Aquarius  Math    Don't Know Don't K…       3     9       9\n#> 5     5 male       4 Scorpio   Gym     Don't Know Don't K…       1     9      10\n#> 6     6 male       4 Pisces    Gym     Extravert  Optimist       2     9      20\n#> # … with 7 more variables: HrsHomework <dbl>, SpendTime1 <chr>,\n#> #   SpendTime2 <chr>, Self1 <chr>, Self2 <chr>, Career <chr>, Superpower <chr>,\n#> #   and abbreviated variable names ¹​ScreenTime, ²​PhysActive\ntail(df)\n#> # A tibble: 6 × 17\n#>      ID Gender Grade Horoscope   Subject IntExt    OptPest Scree…¹ Sleep PhysA…²\n#>   <dbl> <chr>  <dbl> <chr>       <chr>   <chr>     <chr>     <dbl> <dbl>   <dbl>\n#> 1   180 male       6 Capricorn   Math    Extravert Optimi…       2     9      10\n#> 2   181 female     6 Aries       Gym     Extravert Pessim…       5     6       7\n#> 3   182 male       6 Sagittarius Math    Extravert Optimi…       1    11      13\n#> 4   183 male       6 Cancer      Gym     Extravert Optimi…       3     9      11\n#> 5   184 female     6 Aries       Gym     Extravert Optimi…       2     9       7\n#> 6   185 female     6 Gemini      Art     Introvert Pessim…       5     9       7\n#> # … with 7 more variables: HrsHomework <dbl>, SpendTime1 <chr>,\n#> #   SpendTime2 <chr>, Self1 <chr>, Self2 <chr>, Career <chr>, Superpower <chr>,\n#> #   and abbreviated variable names ¹​ScreenTime, ²​PhysActive\n\nDIM\n\ndim(df)\n#> [1] 185  17\n\nGLIMPSE\nFunctie glimpse uit dplyr package toont alle variabelen en het type. Alsmede een voorbeeld van de inhoud. Erg handig voor een overzicht.\n\nglimpse(df)\n#> Rows: 185\n#> Columns: 17\n#> $ ID          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n#> $ Gender      <chr> \"male\", \"female\", \"male\", \"male\", \"male\", \"male\", \"male\", …\n#> $ Grade       <dbl> 4, 4, 4, 4, 4, 4, 3, 6, 6, 6, 4, 4, 4, 7, 8, 8, 8, 8, 8, 8…\n#> $ Horoscope   <chr> \"Scorpio\", \"Capricorn\", \"Taurus\", \"Aquarius\", \"Scorpio\", \"…\n#> $ Subject     <chr> \"Math\", \"Gym\", \"Math\", \"Math\", \"Gym\", \"Gym\", \"Art\", \"Math\"…\n#> $ IntExt      <chr> \"Extravert\", \"Extravert\", \"Introvert\", \"Don't Know\", \"Don'…\n#> $ OptPest     <chr> \"Optimist\", \"Optimist\", \"Optimist\", \"Don't Know\", \"Don't K…\n#> $ ScreenTime  <dbl> 1, 1, 4, 3, 1, 2, 1, 4, 6, 3, 1, 1, 0, 5, 6, 5, 8, 4, 2, 3…\n#> $ Sleep       <dbl> 7, 8, 9, 9, 9, 9, 11, 9, 8, 9, 10, 10, 9, 8, 9, 7, 7, 8, 9…\n#> $ PhysActive  <dbl> 10, 5, 22, 9, 10, 20, 4, 12, 4, 12, 5, 5, 5, 14, 25, 6, 2,…\n#> $ HrsHomework <dbl> 10, 0, 1, 1, 1, 2, 14, 21, 6, 3, 0, 0, 0, 4, 2, 3, 0, 0, 3…\n#> $ SpendTime1  <chr> \"baseball\", \"playing outside\", \"video games\", \"video games…\n#> $ SpendTime2  <chr> \"relaxing\", \"swimming\", \"soccer\", \"sports\", \"hanging out\",…\n#> $ Self1       <chr> \"active\", \"kind\", \"active\", \"active\", \"intellegent\", \"funn…\n#> $ Self2       <chr> \"competitive\", \"active\", \"creative\", \"responsible\", \"stron…\n#> $ Career      <chr> \"professional baseball player\", \"Teacher\", \"professional s…\n#> $ Superpower  <chr> \"sonic speed\", \"power to grant wishes\", \"powerful kick\", \"…\n\nSUMMARY\nFunctie summary toon elke variabele, gegevenstype en wat andere kenmerken die vooral nuttig zijn voor numerieke variabelen.\nSKIM\nFunctie skim uit skimr package is een goede aanvulling op summary. Toont naast numerieke kenmerken tevens ontbrekende waarden, kwartielinfo en een inline histogram.\n\nskimr::skim(df)\n\n\nData summary\n\n\nName\ndf\n\n\nNumber of rows\n185\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n11\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1.00\n4\n14\n0\n3\n0\n\n\nHoroscope\n0\n1.00\n3\n11\n0\n12\n0\n\n\nSubject\n1\n0.99\n3\n7\n0\n5\n0\n\n\nIntExt\n0\n1.00\n9\n10\n0\n3\n0\n\n\nOptPest\n0\n1.00\n8\n10\n0\n3\n0\n\n\nSpendTime1\n0\n1.00\n2\n26\n0\n95\n0\n\n\nSpendTime2\n0\n1.00\n2\n22\n0\n107\n0\n\n\nSelf1\n2\n0.99\n3\n16\n0\n103\n0\n\n\nSelf2\n1\n0.99\n3\n19\n0\n101\n0\n\n\nCareer\n2\n0.99\n3\n28\n0\n106\n0\n\n\nSuperpower\n8\n0.96\n3\n30\n0\n100\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nID\n0\n1.00\n93.00\n53.55\n1\n47\n93\n139\n185\n▇▇▇▇▇\n\n\nGrade\n0\n1.00\n5.74\n1.39\n3\n5\n6\n7\n8\n▆▆▇▂▅\n\n\nScreenTime\n0\n1.00\n3.00\n2.32\n0\n1\n3\n4\n18\n▇▃▁▁▁\n\n\nSleep\n0\n1.00\n8.64\n1.54\n2\n8\n9\n10\n12\n▁▁▅▇▁\n\n\nPhysActive\n1\n0.99\n11.52\n11.81\n0\n6\n9\n12\n82\n▇▁▁▁▁\n\n\nHrsHomework\n0\n1.00\n4.17\n4.79\n0\n1\n3\n6\n35\n▇▁▁▁▁\n\n\n\n\n\nCREATE_REPORT in DataExplorer\nDeze mooie functie maakt een volledig gegevensprofiel van het dataframe. En produceert een html-bestand met de basisstatistieken, structuur, ontbrekende gegevens, distributie-visualisaties, correlatiematrix en hoofdcomponentenanalyse voor het dataframe!\n\nDataExplorer::create_report(df)"
  },
  {
    "objectID": "eda.html#sec-eda-toothgrowth",
    "href": "eda.html#sec-eda-toothgrowth",
    "title": "11  Exploratieve Data Analyse (EDA)",
    "section": "11.2 ToothGrowth",
    "text": "11.2 ToothGrowth\nToothGrowth is een gegevensverzameling van een onzerzoek naar het effect van Vitamine C op de tandgroei van Guinese biggetjes. De verzameling bevat 60 waarnemingen van 3 variabelen:\n\nlen, lengte tand\nsupp, type toediening, OJ = Orange Juice, VC = Vitamine C in de vorm van ascorbinezuur\ndose, dosis in mg/dag\n\n\nstr(ToothGrowth)\n#> 'data.frame':    60 obs. of  3 variables:\n#>  $ len : num  4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ...\n#>  $ supp: Factor w/ 2 levels \"OJ\",\"VC\": 2 2 2 2 2 2 2 2 2 2 ...\n#>  $ dose: num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n\nKwalitatieve variabele\n\n#Frequentietabel\ntable(ToothGrowth$supp)\n#> \n#> OJ VC \n#> 30 30\n\n#Proportionele frequenties\nprop.table(table(ToothGrowth$supp))\n#> \n#>  OJ  VC \n#> 0.5 0.5\n\n#Procentuele frequenties\nprop.table(table(ToothGrowth$supp))*100\n#> \n#> OJ VC \n#> 50 50\n\nNumerieke variabele\n\n#Gemiddelde\nmean(ToothGrowth$len, na.rm = TRUE)\n#> [1] 18.8\n\n#Mediaan\nmedian(ToothGrowth$len, na.rm = TRUE)\n#> [1] 19.2\n\n#Modus (hiervoor bestaat geen rechtstreekse functie)\nwhich.max(table(ToothGrowth$len))\n#> 26.4 \n#>   36\n\n#Variantie\nvar(ToothGrowth$len)\n#> [1] 58.5\n\n#Standaarddeviatie\nsd(ToothGrowth$len)\n#> [1] 7.65\n\nDoor naar de vorm van de gegevens te kijken probeer je een indruk te krijgen van de scheefheid (skewness) en pieken in de verdeling (kurtosis). Meestal worden hiervoor histogrammen, dichtheidsgrafieken en boxplots gebruikt.\n\n#Histogram met dichtheidslijn\nhist(ToothGrowth$len, col = \"lightblue\", probability = TRUE)\nlines(density(ToothGrowth$len))\n\n\n\n\n\n\n\n\nSamenvatting van meerdere variabelen tegelijk\n\nsummary(ToothGrowth)\n#>       len       supp         dose     \n#>  Min.   : 4.2   OJ:30   Min.   :0.50  \n#>  1st Qu.:13.1   VC:30   1st Qu.:0.50  \n#>  Median :19.2           Median :1.00  \n#>  Mean   :18.8           Mean   :1.17  \n#>  3rd Qu.:25.3           3rd Qu.:2.00  \n#>  Max.   :33.9           Max.   :2.00\n\nDe functie describe() uit package Hmisc geeft wat meer gedetailleerde informatie over de variabelen.\n\nHmisc::describe(ToothGrowth)\n#> ToothGrowth \n#> \n#>  3  Variables      60  Observations\n#> --------------------------------------------------------------------------------\n#> len \n#>        n  missing distinct     Info     Mean      Gmd      .05      .10 \n#>       60        0       43    0.999    18.81    8.839     6.37     8.11 \n#>      .25      .50      .75      .90      .95 \n#>    13.07    19.25    25.27    27.30    29.57 \n#> \n#> lowest :  4.2  5.2  5.8  6.4  7.0, highest: 29.4 29.5 30.9 32.5 33.9\n#> --------------------------------------------------------------------------------\n#> supp \n#>        n  missing distinct \n#>       60        0        2 \n#>                   \n#> Value       OJ  VC\n#> Frequency   30  30\n#> Proportion 0.5 0.5\n#> --------------------------------------------------------------------------------\n#> dose \n#>        n  missing distinct     Info     Mean      Gmd \n#>       60        0        3    0.889    1.167    0.678 \n#>                             \n#> Value        0.5   1.0   2.0\n#> Frequency     20    20    20\n#> Proportion 0.333 0.333 0.333\n#> --------------------------------------------------------------------------------\n\nEn de functie describe uit packagepsych` geeft bijna alle hiervoor genoemde informatie. Een mooie functie\n\npsych::describe(ToothGrowth)\n#>       vars  n  mean   sd median trimmed  mad min  max range  skew kurtosis   se\n#> len      1 60 18.81 7.65   19.2   18.95 9.04 4.2 33.9  29.7 -0.14    -1.04 0.99\n#> supp*    2 60  1.50 0.50    1.5    1.50 0.74 1.0  2.0   1.0  0.00    -2.03 0.07\n#> dose     3 60  1.17 0.63    1.0    1.15 0.74 0.5  2.0   1.5  0.37    -1.55 0.08"
  },
  {
    "objectID": "eda.html#sec-eda-kruistabellen",
    "href": "eda.html#sec-eda-kruistabellen",
    "title": "11  Exploratieve Data Analyse (EDA)",
    "section": "11.3 Kruistabellen",
    "text": "11.3 Kruistabellen\nBron: Contingency Tables in R\nEen veel voorkomende manier om categoriale gegevens weer te geven en te analyseren is met kruistabellen. Als voorbeeld wordt met de Wage dataset uit package ISLR gewerkt (zie Calibre boek “Introduction to Statistical Learning”, Gareth James e.a.). Deze bevat loon- en andere gegevens (totaal 11 variabelen) voor een groep van 3000 mannelijke arbeiders in de Mid-Atlantische regio. De variabelen zijn:\n\nyear: Jaar waarin de looninformatie werd geregistreerd\nage: Leeftijd van de werknemer\nmarit1: Een factor met niveaus voor de burgerlijke staat:\n\nNever married (Nooit getrouwd)\nMarried (Getrouwd)\nWidowed (Weduwnaar)\nDivorced (Gescheiden)\nSeparated (Gescheiden)\n\nrace: Een factor met niveaus voor ras:\n\nWhite (Blank)\nBlack (Zwar)\nAsian (Aziatisch)\nOther (Anders)\n\neducation: Een factor met niveaus voor het opleidingsniveau:\n\n< HS Grad\nHS Grad\nSomeCollege\nCollege Grad\nAdvanced Degree\n\nregion: Regio van het land (uitsluitend mid-atlantic)\njobclass: Een factor met niveaus voor de soort baan:\n\nIndustrial (Industrieel)\nInformation (Informatie)\n\nhealth: Een factor met niveaus voor de gezondheidstoestand van de werknemer:\n\n< =Good (Goed)\n\n=Very Good (Zeer goed)\n\n\nhealth_ins: Een factor met niveaus die aangeeft of de werknemer een ziektekostenverzekering heeft:\n\nYes (Ja)\nNo (Nee)\n\nlogwage: Natuurlijke logaritme van brutoloon werknemer\nwage: Brutoloon werknemer\n\n\n11.3.1 Tweezijdige kruistabel\nWanneer je een kruistabel maakt van variabele \\(X\\) met \\(m\\) categorieén met variabele $Y$ met n categorieë n krijg je mxn mogelijke combinaties.\nAls eerste oefening wordt een nieuwe variabele loon_cat gemaakt met twee waarden “Bovengemiddeld” en “Ondergemiddeld” respectievelijk aangevend of het loon boven of onder het gemiddelde zit.\n\nsalaris <- ISLR2::Wage\nsalaris$loon_cat <- as.factor(ifelse(salaris$wage > median(salaris$wage), \n                                  \"Bovengemiddeld\", \"Ondergemiddeld\"))\n\nOm te onderzoeken of er een relatie is tussen loon_cat en jobclass wordt een kruistabel gemaakt.\n\nktbl <- table(salaris$jobclass, salaris$loon_cat)\nknitr::kable(ktbl)\n\n\n\n\n\nBovengemiddeld\nOndergemiddeld\n\n\n\n\n1. Industrial\n629\n915\n\n\n2. Information\n854\n602\n\n\n\n\n\nMet de functie addmargins() kun je rij- en kolomtotalen toevoegen.\n\nknitr::kable(addmargins(ktbl))\n\n\n\n\n\nBovengemiddeld\nOndergemiddeld\nSum\n\n\n\n\n1. Industrial\n629\n915\n1544\n\n\n2. Information\n854\n602\n1456\n\n\nSum\n1483\n1517\n3000\n\n\n\n\n\nFracties in kruistabellen\nIn plaats van aantallen kun je ook fracties weergeven, zowel fracties van het overall totaal, als van het rijtotaal en kolomtaal.\n\n# overall fractie\nknitr::kable(prop.table(ktbl), digits = 4)\n\n\n\n\n\nBovengemiddeld\nOndergemiddeld\n\n\n\n\n1. Industrial\n0.210\n0.305\n\n\n2. Information\n0.285\n0.201\n\n\n\n\n\n# rijtotaal fractie\nknitr::kable(prop.table(ktbl, margin = 1), digits = 4)\n\n\n\n\n\nBovengemiddeld\nOndergemiddeld\n\n\n\n\n1. Industrial\n0.407\n0.593\n\n\n2. Information\n0.587\n0.413\n\n\n\n\n\n# rijtotaal fractie\nknitr::kable(prop.table(ktbl, margin = 2), digits = 4)\n\n\n\n\n\nBovengemiddeld\nOndergemiddeld\n\n\n\n\n1. Industrial\n0.424\n0.603\n\n\n2. Information\n0.576\n0.397\n\n\n\n\n\nmosaic grafiek\nDe meest geschikte manier om de kruistabellen grafisch weer te geven, zijn mosaic grafieken. Dat kan met de standaard in R aanwezige functie mosaicplot().\n\nmosaicplot(ktbl)\n\n\n\n\n\n\n\n\nUit deze grafiek kun je gemakkelijk zien dat in de sector Industrial het percentage mensen dat onder het gemiddelde zit, hoger is in vergelijking met degenen die in de sector Information werken.\nChi-kwadraat toets\n\nchisq.test(ktbl)\n#> \n#>  Pearson's Chi-squared test with Yates' continuity correction\n#> \n#> data:  ktbl\n#> X-squared = 96, df = 1, p-value <2e-16\n\nZoals je kunt zien is de p-waarde minder dan 5%, dus kun je de nulhypothese afwijzen dat de jobclass onafhankelijk is van het gemiddelde loon."
  },
  {
    "objectID": "eda.html#sec-eda-diamonds",
    "href": "eda.html#sec-eda-diamonds",
    "title": "11  Exploratieve Data Analyse (EDA)",
    "section": "11.4 Diamonds",
    "text": "11.4 Diamonds\nKorte inspectie data\n\nhead(diamonds)\n#> # A tibble: 6 × 10\n#>   carat cut       color clarity depth table price     x     y     z\n#>   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#> 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#> 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#> 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#> 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#> 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#> 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\ntail(diamonds)\n#> # A tibble: 6 × 10\n#>   carat cut       color clarity depth table price     x     y     z\n#>   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#> 1  0.72 Premium   D     SI1      62.7    59  2757  5.69  5.73  3.58\n#> 2  0.72 Ideal     D     SI1      60.8    57  2757  5.75  5.76  3.5 \n#> 3  0.72 Good      D     SI1      63.1    55  2757  5.69  5.75  3.61\n#> 4  0.7  Very Good D     SI1      62.8    60  2757  5.66  5.68  3.56\n#> 5  0.86 Premium   H     SI2      61      58  2757  6.15  6.12  3.74\n#> 6  0.75 Ideal     D     SI2      62.2    55  2757  5.83  5.87  3.64\n\nStructuur data\n\nstr(diamonds)\n#> tibble [53,940 × 10] (S3: tbl_df/tbl/data.frame)\n#>  $ carat  : num [1:53940] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ...\n#>  $ cut    : Ord.factor w/ 5 levels \"Fair\"<\"Good\"<..: 5 4 2 4 2 3 3 3 1 3 ...\n#>  $ color  : Ord.factor w/ 7 levels \"D\"<\"E\"<\"F\"<\"G\"<..: 2 2 2 6 7 7 6 5 2 5 ...\n#>  $ clarity: Ord.factor w/ 8 levels \"I1\"<\"SI2\"<\"SI1\"<..: 2 3 5 4 2 6 7 3 4 5 ...\n#>  $ depth  : num [1:53940] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ...\n#>  $ table  : num [1:53940] 55 61 65 58 58 57 57 55 61 61 ...\n#>  $ price  : int [1:53940] 326 326 327 334 335 336 336 337 337 338 ...\n#>  $ x      : num [1:53940] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ...\n#>  $ y      : num [1:53940] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ...\n#>  $ z      : num [1:53940] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ...\n\n\n1 variabele\nSamenvatting\n\nsummary(diamonds$price)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>     326     950    2401    3933    5324   18823\n\nBoxplot\n\nboxplot(diamonds$price, col = 'lightblue', xlab = 'Aantal', ylab = 'Price', main = 'Boxplot')\n\n\n\n\n\n\n\n\nLog transformatie voor ondersteuning normalisatie data.\n\nboxplot(log(diamonds$price), col = 'lightblue', xlab = 'Aantal', ylab = 'Price', main = 'Boxplot')\n\n\n\n\n\n\n\n\nHistogram\n\nhist(diamonds$price, breaks = 10, col = 'lightblue', xlab = 'Price', main  = 'Histogram van Price')\n\n\n\n\n\n\n\n\n\nHet is duidelijk dat meer dan 25.000 diamanten ongeveer $2000 zullen kosten.\nEr zijn 3000-5000 diamanten waarvan de prijs boven de $10000 ligt.\nDistributie is rechts scheef. Dit wijst op de aanwezigheid van uitbijters aan. Onderzoek deze uitbijters.\n\nStaafdiagram\n\nplot(diamonds$cut, col = 'lightblue', xlab=\"cut\", main=\"Staafdiagram\")\n\n\n\n\n\n\n\n\n\n\nMeerdere variabelen\nBoxplots\n\nboxplot(carat ~ cut, data = diamonds, col = \"lightblue\", main = 'Boxplots')\n\n\n\n\n\n\n\n\n\nDe beste kwaliteit diamanten kregen het gewicht binnen 2,5\nDiamanten van lage kwaliteitzijn groter in gewicht / maat.\n\nHistogrammen\n\npar(mfrow = c(2, 1), mar = c(4, 4, 2, 1))\nhist(subset(diamonds, cut == 'Fair')$price, col = 'lightblue', xlab = 'Price', ylab = 'Aantal', main = 'Histogram van Cut(Fair) vs Price verdeling')\nhist(subset(diamonds, cut == 'Ideal')$price, col = 'lightblue', xlab = 'Price', ylab = 'Aantal', main = 'Histogram van Cut(Ideal) vs Price verdeling')\n\n\n\n\n\n\n\n\n\nDiamanten van goede kwaliteit minder kosten. Het is een vreemd patroon, maar is waar voor deze data.\nDe diamanten van lage kwaliteit kosten meer.\n\nScatter plots\n\npar(mfrow = c(1, 2), mar = c(5, 4, 2, 1))\n with(subset(diamonds, cut == \"Fair\"), plot(carat, price, main = \"Fair\", col = 'lightblue'))\n with(subset(diamonds, cut == \"Ideal\"), plot(carat, price, main = \"Ideal\", col = 'lightblue'))\n\n\n\n\n\n\n\n\n\nDe prijs van de diamanten is afhankelijk van het gewicht/de grootte van de diamanten.\nDe kwaliteit van diamanten heeft een kleinere bijdrage in vergelijking met het gewicht van diamanten."
  },
  {
    "objectID": "datasplit.html#sec-datasplit-sample",
    "href": "datasplit.html#sec-datasplit-sample",
    "title": "12  Data splitsen",
    "section": "12.1 sample",
    "text": "12.1 sample\nSyntax: sample(x, size, replace = FALSE)\n\nDe dataset mtcars is een dataframe met 32 rijen.\nMet de functie seq_len(nummer) kun je een reeks maken die begint bij 1 en met een stapgrootte van 1 eindigt bij de waarde nummer. Wanneer nummer gelijk is aan het aantal rijen in het dataframe, dan bestaat de reeks dus uit de rijnummers van het dataframe en kan daardoor dienen als index voor het dataframe.\n\nset.seed(123)\n# Bepaal het aantal waarden voor train\nsample_size = round(nrow(mtcars) * perc_train) # Moet geheel getal zijn\n# Maak een reeks rijnummers en trek hier\nsample_id <- sample(seq_len(nrow(mtcars)), size = sample_size)\n# Getrokken rijnummers voor train\nsort(sample_id)\n#>  [1]  3  5  7  8  9 10 11 14 15 17 18 19 20 22 23 26 27 28 29 30 31 32\n\ntrain <- mtcars[sample_id, ]\ntest <- mtcars[-sample_id, ]\n\nEen alternatief voor -index om de rijnummers voor test te krijgen is via setdiff(1:nrow(mtcars), index)."
  },
  {
    "objectID": "datasplit.html#sec-datasplit-sample-int",
    "href": "datasplit.html#sec-datasplit-sample-int",
    "title": "12  Data splitsen",
    "section": "12.2 sample.int",
    "text": "12.2 sample.int\nSyntax: sample.int(n, size, replace = FALSE)\nDit is een variant op sample(), waarbij n het aantal gehele nummers is waaruit gekozen moet worden.\n\nset.seed(123)\n# Bepaal het aantal waarden voor train\nsample_size = round(nrow(mtcars) * perc_train) # Moet geheel getal zijn\nsample_id <- sample.int(n = nrow(mtcars), size = sample_size)\n\ntrain <- mtcars[sample_id, ]\ntest  <- mtcars[-sample_id, ]"
  },
  {
    "objectID": "datasplit.html#sec-datasplit-sample-n",
    "href": "datasplit.html#sec-datasplit-sample-n",
    "title": "12  Data splitsen",
    "section": "12.3 sample_n",
    "text": "12.3 sample_n\nAanwezig in package dplyr.\nSyntax: sample_n(tbl, size, replace = FALSE)\n\ntbl , tabel met data\nsize, het aantal te kiezen rijen\n\nDit is een verpakking (wrapper) rond sample.int().\n\nset.seed(123)\n\nsample_size = round(nrow(mtcars) * perc_train) \n\ntrain <- sample_n(mtcars, sample_size)\n\n# omzetten naar numeriek, omdat rownames() character als resultaat geeft\nsample_id <- as.numeric(rownames(train)) \ntest <- mtcars[-sample_id, ]\n\n\nWanneer je met dplyr werkt en het dataframe (df) heeft geen indexnummers waar je graag mee zou willen werken, dan kun je eenvoudig indexnummers toekennen met de opdracht df <- df %>% mutate(id = row_number(df))."
  },
  {
    "objectID": "datasplit.html#sec-datasplit-sample-frac",
    "href": "datasplit.html#sec-datasplit-sample-frac",
    "title": "12  Data splitsen",
    "section": "12.4 sample_frac",
    "text": "12.4 sample_frac\nAanwezig in package dplyr.\nSyntax: sample_frac(tbl, size, replace = FALSE)\n\nsize, fractie van het aantal te kiezen rijen\n\nDit is een verpakking (wrapper) rond sample.int().\n\nset.seed(123)\n\ntrain <- sample_frac(mtcars, perc_train)\n\n# omzetten naar numeriek, omdat rownames() character als resultaat geeft\nsample_id <- as.numeric(rownames(train)) \ntest <- mtcars[-sample_id, ]"
  },
  {
    "objectID": "datasplit.html#sec-datasplit-createpartition",
    "href": "datasplit.html#sec-datasplit-createpartition",
    "title": "12  Data splitsen",
    "section": "12.5 createDataPartiton",
    "text": "12.5 createDataPartiton\nAanwezig in package caret.\nSyntax: createDataPartition(y, times = 1, p = 0.5, list = TRUE)\n\ny, vector voor afhankelijke variabele\ntimes, het aantal verdelingen dat gemaakt moet worden\np, het percentage gegevens voor training\nlist, logische waarde welke aangeeft of het resultaat in een list (TRUE) of in een matrix (FALSE) moet.\n\nDeze functie kan worden gebruikt om evenwichtige splitsingen van de gegevens te maken. Als y bijvoorbeeld een factor is, vindt de aselecte trekking binnen elke klasse plaats zodat de algehele klasseverdeling van de data behouden blijft.\n\nset.seed(3456)\n\ntrainindex = createDataPartition(iris$Species, p = perc_train, list = FALSE)\ntrain = iris[trainindex, ]\ntest = iris[-trainindex, ]"
  },
  {
    "objectID": "datasplit.html#sec-datasplit-sample-split",
    "href": "datasplit.html#sec-datasplit-sample-split",
    "title": "12  Data splitsen",
    "section": "12.6 sample_split",
    "text": "12.6 sample_split\nAanwezig in package caTools.\nSyntax: sample.split( Y, SplitRatio = 2/3)\n\nY , vector met data labels\n`SplitRatio,\n\nDe functie genereert een vector met TRUE en FALSE waarden, waarbij de fractie van het aantal TRUE waarden gelijk is aan SplitRatio. Met de functie subset() kun je dan de dataset splitsen.\n\nrequire(caTools)\n\nset.seed(123) \nsample = sample.split(iris$Species, SplitRatio = perc_train)\ntrain = subset(iris, sample == TRUE)\ntest  = subset(iris, sample == FALSE)"
  },
  {
    "objectID": "datasplit.html#sec-datasplit-voorbeeld",
    "href": "datasplit.html#sec-datasplit-voorbeeld",
    "title": "12  Data splitsen",
    "section": "12.7 Voorbeeld",
    "text": "12.7 Voorbeeld\nHet volgende is een erg kunstmatig voorbeeld, maar laat wel aardig zien hoe je een dataframe met verschillende waarden voor verschillende variabelen kunt genereren en daarna op basis van een categorievariabele kunt splitsen.\nVan een aantal personen zijn wat kenmerken verzameld, waaronder het lidmaatschap van een groep. Als eerste wordt een dataframe met kenmerken gegenereerd.\n\naantal <- 30\nset.seed(12345)\ngeslacht <- sample(c(\"V\", \"M\"), size = aantal, replace = TRUE)\ngroep <- sample(c(\"XXX\", \"YYY\", \"ZZZ\"), size = aantal, replace = TRUE)\nleeftijd <- sample(18:55, size = aantal, replace = TRUE)\nIQ <- round(rnorm(aantal, mean = 100, sd = 15))\nbeoordeling <- round(runif(aantal, min = 0, max = 6))\nmijndf <- data.frame(geslacht, groep, leeftijd, IQ, beoordeling)\n# Voor een id erbij: mijndf <- data.frame(id = 1:aantal, geslacht,...)\n\nStel nu dat je een model wilt maken waarbij groep de afhankelijke variabele is, en de andere de onafhankelijke varibelen zijn. Voor trainig en validatie van het model wil je deze groep splitsen in 65% voor training en 25% voor test op basis van de waarde voor groep.\n\nperc_train <- .65\nset.seed(3456)\n\ntrainindex = createDataPartition(mijndf$groep, p = perc_train, list = FALSE)\ntrain = mijndf[trainindex, ]\ntest = mijndf[-trainindex, ]\n\ntrain\n#>    geslacht groep leeftijd  IQ beoordeling\n#> 1         M   ZZZ       44 124           2\n#> 4         M   XXX       39 113           1\n#> 5         M   YYY       40 124           5\n#> 7         M   YYY       43  81           2\n#> 9         V   ZZZ       32  88           6\n#> 10        M   XXX       54  84           0\n#> 11        M   XXX       40 135           2\n#> 13        M   YYY       43 114           1\n#> 14        V   XXX       41 112           3\n#> 15        M   XXX       52  88           4\n#> 16        V   ZZZ       22 107           5\n#> 17        M   ZZZ       21 115           1\n#> 18        M   XXX       28 110           3\n#> 19        V   ZZZ       20 116           4\n#> 20        M   XXX       27  95           5\n#> 22        V   YYY       24 115           0\n#> 23        M   YYY       43 128           3\n#> 24        M   ZZZ       21 110           4\n#> 25        V   ZZZ       45  95           2\n#> 26        M   XXX       21 108           4\n#> 27        M   ZZZ       49 112           2\n#> 30        M   YYY       45 128           3\ntest\n#>    geslacht groep leeftijd  IQ beoordeling\n#> 2         V   XXX       51  91           6\n#> 3         M   YYY       52  73           1\n#> 6         M   ZZZ       48 108           5\n#> 8         V   YYY       24 101           2\n#> 12        M   ZZZ       29 121           5\n#> 21        M   XXX       32 137           1\n#> 28        M   ZZZ       35  86           2\n#> 29        M   XXX       18  87           6"
  },
  {
    "objectID": "kde.html#sec-kde-kansvariabelen",
    "href": "kde.html#sec-kde-kansvariabelen",
    "title": "13  Kernel Density Estimation",
    "section": "13.1 Kansvariabelen",
    "text": "13.1 Kansvariabelen\nEen kansvariabele (stochastische variabele, toevalsvariabele) is een grootheid waarvan de waarde een getal is dat afhangt van de toevallige uitkomst van een kansexperiment. Er kunnen twee soorten kansvariabelen onderscheiden worden:\n\ndiscrete - waarbij de kansvariabele vaak wordt aangeduid met het symbool \\(\\underline{k}\\).\n\nHet aantal ogen bij één worp met een dobbelsteen.\nHet aantal keren dat munt gegooid wordt bij 100 worpen met een munt.\n\ncontinue - waarbij de kansvariabele vaak wordt aangeduid met het symbool \\(\\underline{x}\\).\n\nDe wachttijd bij het bellen met een callcentre.\nHet gewicht van personen\n\n\nBij een kansvariabele zijn de mogelijke uitkomsten bekend, liggen vast, maar de waargenomen waarde hangt af van het toeval. Een belangrijk aspect van een kansvariabele is de bijbehorende kansverdeling, die aangeeft wat de kansen zijn op de mogelijke waarden. Een kans ligt altijd tussen 0 en 1 en de som van alle kansen is 1.\nDe beschrijving van de kansen op de diverse uitkomsten wordt kansfunctie (in het discrete geval) of kansdichtheid (in het continue geval) genoemd.\n\n13.1.1 Discrete kansvariabele\nBij een discrete kansvariabele \\(\\underline{k}\\) kan de kansfunctie \\(f(k)\\) beschouwd worden als een weergave van de kansen.\nDefinitie: \\(f(k) = P(\\underline{k} = k)\\)\nWorp met 1 dobbelsteen\n\n\n\n\n\nFiguur 13.1: Worp met 1 dobbelsteen\n\n\n\n\nDit is een discrete versie van een uniforme verdeling.\nVaak wordt er gewerkt met de verdelingsfunctie \\(F(k)\\). In plaats van te rekenen met losse kansen wordt er gerekend met cumulatieve kansen, \\(F(k) = P(\\underline{k} \\le k)\\). Deze functie geeft de kans aan dat de kansvariabele \\(\\underline{k}\\) een waarde aanneemt kleiner of gelijk aan een bepaalde grenswaarde \\(k\\).\n\\(F(k) = \\sum_{j \\le k}f(j)\\)\n\n\n\n\n\nFiguur 13.2: Caumulatieve verdeling van de Worp met 1 dobbelsteen\n\n\n\n\n\n\n13.1.2 Continue kansvariabele\nKon je bij een discrete kansvariabele de kansfunctie \\(f(k)\\) punt voor punt omschrijven, bij een continue kansvariabele kan dat niet omdat ieder “los” punt een kans 0 heeft. Er zijn immers een overaftelbaar mogelijke uitkomsten, waardoor de kans dat een specifieke waarde precies wordt aangenomen, gelijk is aan nul. Daarom moet bij continue kansen altijd gekeken worden naar de kans dat de variabele in een bepaald interval ligt. Bijvoorbeeld dat de kans dat gewicht van een persoon tussen de 75,6 kg en 82,1 kg ligt.\nBij een continue variabele wordt de kans op een bepaalde waarde gedefinieerd met behulp van de kansdichtheid \\(f(x)\\).\nStel \\(\\underline{x}\\) is het lichaamsgewicht van een volwassen man met bijbehorende kansfunctie \\(f(x)\\), dan wordt in een grafiek van \\(f(x)\\) de kans dat het gewicht van iemand tussen de 75 kg en 82 kg is weergegeven door het oppervlak tussen deze grenzen en kan dat berekend worden door te integreren:\n\\(P(75 \\lt \\underline{x} \\lt 80) = (75 \\le \\underline{x} \\le 80) = \\int_{75}^{80}f(x)dx\\)\nDe cumulatieve verdelingsfunctie is gedefinieerd als\n\\(F(x) = \\int_{- \\infty}^{y}f(y)dy\\) met \\(f(y)\\) als een kansdichtheid\nEn de kansdichtheid is dan de afgeleide van de verdelingsfunctie: \\(f(x) = F^{'}(x)\\)"
  },
  {
    "objectID": "kde.html#sec-kde-kde",
    "href": "kde.html#sec-kde-kde",
    "title": "13  Kernel Density Estimation",
    "section": "13.2 KDE",
    "text": "13.2 KDE\nWanneer je een dataset van een continue variabele hebt, dan is de kansdichtheid van die variabele onbekend. Er zijn een aantal methodes om die kansdiachtheid te schatten. Een goede indruk krijg je via een histogram. De keuze van de klassebreedte is hierbij erg belangrijk. Een andere methode is de Kernel Density Estimation (KDE), een vrij complexe techniek welke goede resultaten geeft.\n\n13.2.1 Kernel\nBij de schatting van de kansdichtheid van de variabele worden kernels gebruikt, vandaar de naam.\nEen kernel is een kansdichtheidsfunctie \\(f(x)\\) met de volgende eigenschappen:\n\n\\(f(x)\\) is niet negatief\n\\(f(x)\\) heeft reeele waarden\n\\(f(x)\\) is even, d.w.z. f(x) = f(-x), dus symmetrisch rond Y-as\nzijn definitieve integraal moet gelijk zijn aan 1\n\nBekende kernels zijn de kansdichtheidsfuncties van de uniforme verdeling \\(U[-1,1]\\) en de standaard normale (Gauss) verdeling \\(N(0,1)\\). Zie verder de lijst in wikipedia.\nDe werking van de KDE methode komt er op neer dat wanneer je binnen de kernel verschillende punten dicht bij elkaar hebt waargenomen, de kans op die waarden groter wordt.\nIn wezen wordt bij elk datapunt een kernelfunctie gemaakt met het datapunt in het midden - dit zorgt ervoor dat de kernel symmetrisch is ten opzichte van het datapunt. De kansdichtheidfunctie wordt vervolgens geschat door al deze kernelfuncties op te tellen en te delen door het aantal gegevens om er zeker van te zijn dat deze voldoet aan de 2 eigenschappen van een kansdichtheidfunctie:\n\nIedere mogelijke waarde van functie f(x) is niet-negatief.\nDe definitieve integraal over het waardenbereik is 1. (totale kans = 1)\n\nDit wordt fraai uitgebeeld in https://www.youtube.com/watch?v=x5zLaWT5KPs\nIntuïtief is een kansdichtheidschatting van de kernel een som van “bulten”. Aan elk datapunt wordt een “bult” toegewezen, en de grootte van de “bult” geeft de waarschijnlijkheid weer die is toegewezen aan de waarden rond dat gegevenspunt. Dus als de dataset twee waarden bevat bij x=1,5 en 1 waarde bevat bij x=1, dan is de bult bij x=1,5 twee keer zo groot als de bult bij x=0,5.\nElke “bult” is gecentreerd op het datapunt en spreidt zich symmetrisch uit om de aangrenzende waarden van het datapunt te dekken. Elke kernel heeft een bandbreedte welke de breedte van de “hobbel” bepaalt (de breedte van de omgeving van waarden waaraan waarschijnlijkheid is toegewezen). Een grotere bandbreedte resulteert in een kortere en bredere “bult” die zich verder van het midden uitspreidt en meer waarschijnlijkheid toekent aan de aangrenzende waarden.\nDe KDE heeft twee cruciale componenten:\n\nkernel - een dichtheidfunctie. Gebruikt worden normaal , uniforme , driehoekig , Epanechnikov , quartic , triweight en cosinus\nbandbreedte - vlakt de resulterende gegevens uit de dichtheidsfunctie van de kernel . De bandbreedte heeft dus grote invloed op de visuele weergave van de gegevens . Een scherpe lijn kan geleidelijk gladgestreken worden , totdat de gegevens zo zijn geparafraseerd , dat het niet langer zinvol is. In de formule voor de Kernel dichtheid schatting wordt de bandbreedte weergegeven door de letter \\(h\\).\n\n\n\n13.2.2 Animatie voorbeeld\nBron: Kernel Density Estimation, Matthew Conlen\nSchatting van de kerneldichtheid is een erg handig statistisch hulpmiddel, vaak afgekort tot KDE. Het is een techniek waarmee je een vloeiende curve kunt maken op basis van een set gegevens.\nDit kan handig zijn als je alleen de “vorm” van sommige gegevens wilt visualiseren, als een soort continue vervanging van het discrete histogram. Het kan ook worden gebruikt om punten te genereren die eruitzien alsof ze uit een bepaalde dataset komen - dit gedrag kan eenvoudige simulaties mogelijk maken, waarbij gesimuleerde objecten worden gemodelleerd op basis van echte gegevens.\nTo understand how KDE is used in practice, lets start with some points. The white circles on your screen were sampled from some unknown distribution.\nAs more points build up, their silhouette will roughly correspond to that distribution, however we have no way of knowing its true value.\nThe blue line shows an estimate of the underlying distribution, this is what KDE produces.\nThe KDE algorithm takes a parameter, bandwidth, that affects how “smooth” the resulting curve is. Use the control below to modify bandwidth, and notice how the estimate changes.\nBandwidth: 0.10\nThe KDE is calculated by weighting the distances of all the data points we’ve seen for each location on the blue line. If we’ve seen more points nearby, the estimate is higher, indicating that probability of seeing a point at that location.\nMove your mouse over the graphic to see how the data points contribute to the estimation — the “brighter” a selection is, the more likely that location is. The red curve indicates how the point distances are weighted, and is called the kernel function. The points are colored according to this function.\nChanging the bandwidth changes the shape of the kernel: a lower bandwidth means only points very close to the current position are given any weight, which leads to the estimate looking squiggly; a higher bandwidth means a shallow kernel where distant points can contribute.\nThe concept of weighting the distances of our observations from a particular point, \\(x\\) , can be expressed mathematically as follows:\n\\(\\hat{f}(x) = \\sum_{observations} K(\\frac{x - observation}{bandwith})\\)\nThe variable \\(K\\) represents the kernel function. Using different kernel functions will produce different estimates. Use the dropdown to see how changing the kernel affects the estimate.\nMogelijke functies: Epanechnikov, Normal, Uniform, Triangular, Gauss, …\nWikipedia\nHij heeft een fraaie animatie gemaakt m.b.v. Idyll\nDe broncode voor zijn animatie: https://github.com/mathisonian/kde/\n\n\n13.2.3 Nog een uitleg\nEen kernel wordt gedefinieerd als een gladde functie K, zodanig dat \\(K(x) \\ge 0\\), \\(\\int K(x) dx = 1\\), \\(\\int x K(x) dx = 0\\) en \\(\\sigma^{2}_{K} = \\int x^2 K(x) dx > 0\\)\nEen voorbeeld van een Kernel is Gauss (Normaal) Kernel \\(K(x) = (2\\pi)^{-0,5} e^{-x^2/2}\\)\nDefinitie: gegeven een kernel \\(K\\) en een positief getal \\(h\\), genaamd de bandbreedte, dan wordt de KDE gedefinieerd als \\(\\hat{f}(x) = \\frac{1}{n} \\sum_{i=1}^{n}\\frac{1}{h}K(\\frac{x - X_i}{h})\\) met \\(X_i\\) als gegevenspunt.\nDe bandbreedte \\(h\\) controleert de hoeveelheid smoothing"
  },
  {
    "objectID": "kde.html#sec-kde-oefeningen",
    "href": "kde.html#sec-kde-oefeningen",
    "title": "13  Kernel Density Estimation",
    "section": "13.3 Oefeningen",
    "text": "13.3 Oefeningen\n\nTest 01\nBron: Create Kernel Density Plot in R (7 Examples) | density() Function\nAllereerst wordt wat voorbeelddata gemaakt, in dit geval normaal verdeelde waarden\n\nset.seed(13531)\nx <- rnorm(1000)\n\nHistogram\nEerst een histogram van de data\n\nhist(x, main = \"Histogram van x\")\n\n\n\n\n\n\n\n\nBasis KDE in standaard R\nMet functie density() kun je kernel density schattingen maken. Je kunt bandbreedte en de te gebruiken kernel specificeren\n\nkernel : “gaussian” (default), “epanechnikov”, “rectangular”, “triangular”, “biweight”, “cosine”, “optcosine”\n\n\nplot(density(x), main=\"Kernel Density\")\n\n\n\n\n\n\n\n\nHistogram + density()\nJe kunt ook een dichtheidgrafiek over een histogram leggen.\n\nhist(x, probability = TRUE, main = \"Histogram van x\")\nlines(density(x), col = \"red\")\n\n\n\n\n\n\n\n\nVergelijking van een paar kernels\n\nplot(density(x), col = \"black\")\nlines(density(x, kernel = \"rectangular\"), col = \"red\")\nlines(density(x, kernel = \"epanechnikov\"), col = \"blue\")\nlegend(\"topright\", \n       legend = c(\"gaussian\", \"rectangular\", \"epanechnikov\"), \n       col = c(\"black\", \"red\", \"blue\"),\n       lty = 1)\n\n\n\n\n\n\n\n\nggplot\n\nggplot()+ geom_density(aes(x = x))\n\n\n\n\n\n\n\n\n\n\nTest 02\nBron: The importance of kernel density estimation bandwidth\nGitHub\n\nx <- c(21.370, 19.435, 20.363, 20.632, 20.404, 19.893, 21.511, 19.905, 22.018, 19.93, \n       31.304, 32.286, 28.611, 29.721, 29.866, 30.635, 29.715, 27.343, 27.559, 31.32, \n       39.693, 38.218, 39.828, 41.214, 41.895, 39.569, 39.742, 38.236, 40.460, 39.36, \n       50.455, 50.704, 51.035, 49.391, 50.504, 48.282, 49.215, 49.149, 47.585, 50.03)\nplot(density(x, bw = 5))\nplot(density(x, bw = 2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteressant artikel dat nog veel verder gaat."
  },
  {
    "objectID": "referenties.html",
    "href": "referenties.html",
    "title": "14  Referenties",
    "section": "",
    "text": "6 Common Probability Distributions every data science professional should know, Analytics Vidhya, 2017-09-18\nProbability Distributions in R (Stat 5101, Geyer)\nUnderstanding Data, Thomas Hopper, 2017-06-19\n“Statistiek om mee te werken”, A. Buijs\n\nDriehoekstest\n\nWikipedia - Discrimination testing\nAbout Triangle Testing\nSensory evaluation with the triangle test\nA shiny new triangle test calculator\n\nMaximum Likelihood\n\nAn Introductory Guide to Maximum Likelihood Estimation with a case study in R\nMaximum Likelihood\nDoing Maximum Likelihood Estimation by Hand in R\nFitting a Model by Maximum Likelihood\nMaximum Likelihood for the Normal Distribution\nProbability concepts explained: Maximum likelihood estimation\n\nData splitsen\n\nThe caret package, Max Kuhn\nTutorial to prepare train and test set using dataPreparation\n\nKernel Density Estimation\n\n“Data Analysis with Open Source Tools”, Philipp Janert, Chapter 2\nDensity estimation in R, Henry Deng and Hadley Wickham\nKernel density estimation in R\nAnimating kernel density estimators, leuk en leerzaam\nKernel Density Estimation, Real Statistics, Excel\nKernel dichtheid schatting - Kernel density estimation Kernel dichtheid schatting, van Wikipedia\nContinue stochast, over kansdichtheidsfuncties\nExploratory Data Analysis: Kernel Density Estimation in R on Ozone Pollution Data in New York and Ozonopolis\nCreate Kernel Density Plot in R, tutorial, 7 voorbeelden, density() functie\n“Kernel density estimation” is a convolution of what?"
  },
  {
    "objectID": "normale-verdeling.html#n01-verdeling",
    "href": "normale-verdeling.html#n01-verdeling",
    "title": "Appendix A — Normale verdeling",
    "section": "A.1 N(0,1) verdeling",
    "text": "A.1 N(0,1) verdeling\nMet de basis R plot functie.\n\n# Maak een reeks van 1000 gelijk verdeelde getallen tussen -4 en 4 \nx <- seq(-4, 4, length=1000)\n\n# Maak een vector van waarden die de hoogte van de kansverdeling geeft voor elke waarde in x\nset.seed((1234))\ny <- dnorm(x)\n\n# Maak een spreidingsdiagram, verbind de punten via een lijn (type = \"l\")\n# maak aangepaste labels voor de X-as\nplot(x, y, type = \"l\", lwd = 2, axes = FALSE, xlab = \"\", ylab = \"\")\naxis(1, at = -3:3, labels = c(\"-3sd\", \"-2sd\", \"-1sd\", \"gemid\", \"1sd\", \"2sd\", \"3sd\"))\n\n\n\n\n\n\n\n\nMet de curve functie.\n\ncurve(dnorm, -3.5, 3.5, lwd=2, axes = FALSE, xlab = \"\", ylab = \"\")\naxis(1, at = -3:3, labels = c(\"-3sd\", \"-2sd\", \"-1sd\", \"gemid\", \"1sd\", \"2sd\", \"3sd\"))\n\n\n\n\n\n\n\n\nMet ggplot functie.\n\nggplot(data.frame(x = c(-4, 4)), aes(x = x)) +\nstat_function(fun = dnorm)"
  },
  {
    "objectID": "normale-verdeling.html#n505-verdeling",
    "href": "normale-verdeling.html#n505-verdeling",
    "title": "Appendix A — Normale verdeling",
    "section": "A.2 N(50,5) verdeling",
    "text": "A.2 N(50,5) verdeling\n\n#define population mean and standard deviation\npop_gemid<- 50 # gemiddelde populatie\npop_sd <- 5    # standaarddeviatie populatie\n\n# Maak een reeks van 1000 x-waarden\nx <- seq(-4, 4, length = 1000) * pop_sd + pop_gemid\n\n# Maak een vector van waarden voor de kansdichtheidsfunctie\ny <- dnorm(x, pop_gemid, pop_sd)\n\n# Teken grafiek met aangepaste X-as labels\nplot(x,y, type = \"l\", lwd = 2, axes = FALSE, xlab = \"\", ylab = \"\")\nsd_axis_bounds = 5\naxis_bounds <- seq(-sd_axis_bounds * pop_sd + pop_gemid,\n                    sd_axis_bounds * pop_sd + pop_gemid,\n                    by = pop_sd)\naxis(side = 1, at = axis_bounds, pos = 0)\nabline(v= pop_gemid)\n\n\n\n\n\n\n\n\n\nA.2.1 Arceringen\nplot functie\nUitleg hierover op https://r-coder.com/normal-distribution-r/.\n\nx <- seq(-4, 4, length=100)\ny <- dnorm(x)\n\n# nieuw gebied voor inkleuring\nog <- min(x) # ondergrens\nbg <- 1      # bovengrens\nx2 <- seq(og, bg, length = 100)\ny2 <- dnorm(x2)\n\nplot(x, y, type = \"l\", lwd = 2) # Teken grafiek\npolygon(x = c(og,x2,bg), y=c(0,y2,0), col = \"lightgrey\")\ntext(x=-1.5, y=0.05, labels = \"tekst\", adj = c(0,0))\n\n\n\n\n\n\n\n\nggplot\nuitleg: https://github.com/tidyverse/ggplot2/issues/1528\n\nggplot(NULL, aes(c(-4,4))) +\n    geom_line(stat = \"function\", fun = dnorm, xlim=c(-4,4)) +\n    scale_x_continuous(limits = c(-4,4), breaks = seq(-4, 4, by = 1)) +\n    geom_area(stat = \"function\", fun = dnorm, fill = \"grey80\", xlim = c(-4, 1)) +\n    labs(x = \"x\", y = \"f(x)\") +\n    annotate(geom = \"text\", x = -1.0, y = 0.05, hjust = 0, label = \"oppervlak\")\n\n\n\n\n\n\n\n\n\nA.2.1.1 Functie\n\nnormal_area <- function(mean = 0, sd = 1, lb, ub, acolor = \"lightgray\", ...) {\n    x <- seq(mean - 3 * sd, mean + 3 * sd, length = 100) \n    \n    if (missing(lb)) {\n       lb <- min(x)\n    }\n    if (missing(ub)) {\n        ub <- max(x)\n    }\n\n    x2 <- seq(lb, ub, length = 100)    \n    plot(x, dnorm(x, mean, sd), type = \"n\", ylab = \"\")\n   \n    y <- dnorm(x2, mean, sd)\n    polygon(c(lb, x2, ub), c(0, y, 0), col = acolor)\n    lines(x, dnorm(x, mean, sd), type = \"l\", ...)\n}\n\nArgumenten functie:\n\nmean: gemiddelde\nsd: standaard deviatie\nlb: ondergrens gearceerde gebied\nub: bovengrens gearceerde gebied\nacolor: kleur gearceerde gebied\n…: additionele argumenten voor de lijngrafiek\n\n\nnormal_area(mean = 0, sd = 1, lb = -1, ub = 2, lwd = 2)\ntext(x = 0, y = 0.1, labels = \"oppervlak\")\n\n\n\n\n\n\n\n\n\n\n\nA.2.2 Divers\nnormaal\n\nn <- 1000\nzs <- seq(-4, 4, length=n) # z-waarden\nset.seed(1234)\nnd <- dnorm(zs)            # dichtheid normale verdeling\n\nfunctie voor aangepast histogram\n\nmyhist<- function(x, ...){\n  hist(x, breaks = 30, xlab = \"Z\", ylab = \"\",  yaxt='n', freq = FALSE, ...)\n  lines(x = zs, y = nd, type = \"l\", col = \"red\", lwd = 2)\n}\n\n\nset.seed(1234)\ngaussverdeling <- rnorm(1000)\nmyhist(gaussverdeling, main = \"Gauss verdeling\")\n\n\n\n\n\n\n\n\nDe rode curve toont de Gauss-verdeling, terwijl het histogram de verdeling toont van 1000 willekeurige gegenereerde getallen tussen -4 en 4. Zoals je kunt zien, komt de bovenkant van de balken in het histogram mooi overeen met de Gauss-verdeling. Als onze dataset perfect normaal verdeeld zou zijn, zou het midden van de bovenkant van elke balk op de rode curve vallen.\nrechts scheef\n\n# scheef_recht is de dataset die vergeleken wordt met de Gauss verdeling\nscheef_rechts <- c(gaussverdeling[gaussverdeling > 0] * 2.5, gaussverdeling)\nmyhist(scheef_rechts, main = \"Rechts scheef\", ylim = c(0, max(nd)))\n\n\n\n\n\n\n\n\nBij “rechts scheef”, wat betekent worden de meeste gegevens verdeeld met een lange “staart” van gegevens die zich naar rechts uitstrekt.\nlinks scheef\nBij “links scheef” strekt de staart zich naar links uit.\n\n# scheef_links is de dataset die vergeleken wordt met de Gauss verdeling\nscheef_links <- c(gaussverdeling[gaussverdeling < 0] * 2.5, gaussverdeling)\nmyhist(scheef_links, main = \"Links scheef\", ylim = c(0, max(nd)))\n\n\n\n\n\n\n\n\nDe twee histogrammen zijn bijna spiegelbeelden van elkaar (over de Y-as)."
  },
  {
    "objectID": "normale-verdeling.html#uitschieters",
    "href": "normale-verdeling.html#uitschieters",
    "title": "Appendix A — Normale verdeling",
    "section": "A.3 Uitschieters",
    "text": "A.3 Uitschieters\n\nOutliers detection in R\nDetect outliers in a dataset by statistical methods (with R code)"
  },
  {
    "objectID": "normale-verdeling.html#test-voor-normale-verdeling",
    "href": "normale-verdeling.html#test-voor-normale-verdeling",
    "title": "Appendix A — Normale verdeling",
    "section": "A.4 Test voor normale verdeling",
    "text": "A.4 Test voor normale verdeling\nBron: https://datasciencetut.com/test-for-normal-distribution-in-r-quick-guide/\nTest for Normal Distribution in R, Many statistical tests, such as correlation, regression, t-test, and analysis of variance (ANOVA), presuppose that the data has particular features.\nThey demand that the data follow a normal or Gaussian distribution. These tests are known as parametric tests since their validity is determined by the data distribution.\nNormality and other assumptions made by these tests should be considered carefully in order to obtain meaningful results and interpretations from the research.\nWe should do some preliminary tests before utilizing a parametric test to ensure that the test assumptions are met.\nNon-parametric tests are indicated in cases where the assumptions are violated.\nWe’ll go over how to check the data for normality using visual examination and significance tests.\nVeel statistische tests, zoals correlatie, regressie, t-test en variantieanalyse (ANOVA), veronderstellen dat de gegevens bepaalde kenmerken hebben. Ze eisen dat de gegevens een normale of Gauss-verdeling volgen. Deze tests staan bekend als parametrische tests omdat hun geldigheid wordt bepaald door de gegevensdistributie. Normaliteit en andere veronderstellingen die door deze tests worden gemaakt, moeten zorgvuldig worden overwogen om zinvolle resultaten en interpretaties van het onderzoek te verkrijgen. Je moet enkele voorbereidende tests doen voordat je een parametrische test kunt gebruiken om ervoor te zorgen dat aan de testaannames wordt voldaan.\nNiet-parametrische tests zijn aangewezen in gevallen waarin de aannames worden geschonden.\nHet controleren van de gegevens op normaliteit wordt hier gedaan met behulp van visueel onderzoek en significantietests.\n\nlibrary(ggpubr)\n\n\ndata <- ToothGrowth\nhead(data)\n#>    len supp dose\n#> 1  4.2   VC  0.5\n#> 2 11.5   VC  0.5\n#> 3  7.3   VC  0.5\n#> 4  5.8   VC  0.5\n#> 5  6.4   VC  0.5\n#> 6 10.0   VC  0.5\n\nGecontroleerd wordt len, de variabele voor de tandlengte, normaal verdeeld is.\nWe kunnen de gegevensdistributie negeren en parametrisch testen gebruiken als de steekproefomvang groot genoeg is (n > 30). De centrale limietstelling stelt dat als de steekproefomvang groot genoeg is (n > 30), de steekproevenverdeling normaal zal zijn, ongeacht de verdelingsitems.\nNormaliteit kan visueel worden beoordeeld [normale plots (histogram), Q-Q-plot (kwantiel-kwantielplot)] of door significantietests om consistentie te verzekeren.\n\nA.4.1 Visuale technieken\nVisuele controles op normaliteit omvatten de dichtheidsplot en de Q-Q-plot. De dichtheidsplot wordt gebruikt om te bepalen of de verdeling klokvormig is.\n\nggpubr::ggdensity(data$len,\n          main = \"Density plot\",\n          xlab = \"Tooth length\")\n\n\n\n\n\n\n\n\nDe Q-Q-plot (ook bekend als de kwantiel-kwantielplot) geeft de relatie weer tussen een steekproef en de normale verdeling. Er is ook een referentielijn van 45 graden uitgezet.\n\nggpubr::ggqqplot(data$len)\n\n\n\n\n\n\n\n\nJe kunt ook de functie qqPlot() uit package car gebruiken.\n\ncar::qqPlot(data$len)\n#> [1] 23  1\n\n\n\n\n\n\n\n\nJe kunt hieruit normaliteit afleiden omdat alle punten ongeveer langs deze referentielijn liggen.\n\n\nA.4.2 Test voor normaliteit\nDe beschrijving van visuele inspectie in de vorige sectie is vaak onjuist. Een significantietest kan worden gebruikt om te bepalen of gegevens een significante afwijking van normaal vertonen door de steekproefverdeling te vergelijken met een normale verdeling. De Kolmogorov-Smirnov (K-S) normaliteitstest en de Shapiro-test Wilk’s zijn twee voorbeelden van normaliteitstests.\n“De steekproefverdeling is normaal”, is de nulhypothese in deze tests. De verdeling is niet-normaal als de test significant is.\nVoor normaliteitstesten heeft Shapiro-benadering Wilk’s vaak de voorkeur omdat deze meer kracht heeft dan K-S. Het is gebaseerd op de associatie van de gegevens met de relevante normale scores.\nHet is vermeldenswaard dat de normaliteitstest wordt beïnvloed door de steekproefomvang. De meeste kleine steekproeven slagen voor normaliteitstesten.\nOm de beste beslissing te nemen, is het cruciaal om visuele beoordeling en significantietests te combineren.\nDe Shapiro-Wilk-test van normaliteit voor één variabele (univariate) kan worden uitgevoerd met de functie shapiro.test().\n\nshapiro.test(data$len)\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  data$len\n#> W = 1, p-value = 0.1\n\nConclusie\nDe p-waarde > 0,05 in de uitvoer geeft aan dat de gegevensverdeling niet wezenlijk verschilt van de normale verdeling. Anders gezegd, je kunt uitgaan van normaliteit."
  }
]